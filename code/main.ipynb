{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "725f1f3d-c3b4-45db-a9b8-889964830e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing modules from PySpark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import monotonically_increasing_id, current_timestamp, date_format, regexp_replace, col, split, lower, to_date, substring_index, substring\n",
    "from pyspark.sql.functions import initcap, regexp_extract, expr, when, row_number, count, explode, trim, length, lit, array_min, array_max, array_remove, to_timestamp, concat_ws\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Park Data Normalization\") \\\n",
    "    .config(\"spark.driver.extraClassPath\", \"jdbc/postgresql-42.2.23.jar\") \\\n",
    "    .getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05f2d17-5687-426a-b42f-d64355ea8a58",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45e080a9-ab44-4c8c-be6f-4ae793f0e08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_table_db(spark, jdbc_url, connection_properties, table_name, max_cond_sql, common_rows_sql, df_table):\n",
    "    try:\n",
    "        # Check if the table exists\n",
    "        existing_tables = spark.read.jdbc(url=jdbc_url, table=\"information_schema.tables\", properties=connection_properties)\n",
    "    \n",
    "        if existing_tables.filter((existing_tables[\"table_name\"] == table_name) & (existing_tables[\"table_schema\"] == \"public\")).count() == 0:\n",
    "            raise AnalysisException(\"Table '{}' does not exist in the database.\".format(table_name))\n",
    "    \n",
    "        # Load the table into a Spark DataFrame\n",
    "        table_db = spark.read.jdbc(url=jdbc_url, table=table_name, properties=connection_properties)\n",
    "        \n",
    "        # Create a temporary view for the database table\n",
    "        table_db.createOrReplaceTempView(\"View_table_db\")\n",
    "\n",
    "        # Get the maximum value of ParkConditionID from View_ParkConditions_db\n",
    "        max_table_cond_id = spark.sql(max_cond_sql).collect()[0][\"max_table_cond_id\"]\n",
    "        \n",
    "        # Format the common_rows query with the obtained maximum ID\n",
    "        formatted_common_rows_sql = common_rows_sql.format(max_table_cond_id=max_table_cond_id)\n",
    "        \n",
    "        # Execute the SQL query to obtain common records\n",
    "        common_rows = spark.sql(formatted_common_rows_sql)\n",
    "\n",
    "        # Assuming you have a DataFrame called df\n",
    "        rows = common_rows.collect()\n",
    "        \n",
    "        # Get the names of the original columns\n",
    "        column_names = common_rows.columns\n",
    "        \n",
    "        # Create a list of tuples with original column names\n",
    "        list_of_tuples = [tuple(row[column_names.index(name)] for name in column_names) for row in rows]\n",
    "        \n",
    "        # Create DataFrame\n",
    "        df_table = spark.createDataFrame(list_of_tuples, column_names)\n",
    "        # Sort DataFrame by the first column\n",
    "        df_table = df_table.orderBy(column_names[0])\n",
    "        \n",
    "        # Write the DataFrame into the PostgreSQL table\n",
    "        df_table.write.jdbc(url=jdbc_url, table=table_name, mode=\"overwrite\", properties=connection_properties)\n",
    "\n",
    "    except AnalysisException as e:\n",
    "        # Print the error message and exception type\n",
    "        # print(f\"An error occurred: {str(e)}\")\n",
    "        # print(f\"Exception type: {type(e).__name__}\")\n",
    "        \n",
    "        # Write the DataFrame into the PostgreSQL table\n",
    "        df_table.write.jdbc(url=jdbc_url, table=table_name, mode=\"overwrite\", properties=connection_properties)\n",
    "        \n",
    "        print(\"DataFrame successfully exported to table '{}' in the PostgreSQL database.\".format(table_name))\n",
    "    \n",
    "    # Return the DataFrame\n",
    "    df_table.show()\n",
    "    return df_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be678655-e277-4df2-9603-00e85fb5da50",
   "metadata": {},
   "source": [
    "# Database Conection (PostgreSQL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "129e1448-6b90-49b2-bb3f-8760dc64bab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|        current_time|\n",
      "+--------------------+\n",
      "|2024-04-29 23:49:...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# JDBC connection configuration\n",
    "jdbc_url = \"jdbc:postgresql://postgres:5432/verusen\"\n",
    "connection_properties = {\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"postgres\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    # Conection Test\n",
    "    df = spark.read.jdbc(url=jdbc_url, table=\"(SELECT CURRENT_TIMESTAMP AS current_time) AS temp\", properties=connection_properties)\n",
    "    df.show()\n",
    "    \n",
    "except Exception as e:\n",
    "    # If there's any error while connecting or executing the query, display an error message.\n",
    "    print(\"Error al conectar a PostgreSQL o al ejecutar la consulta:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c251761-20fb-4efb-a4da-5a40fb97aa8f",
   "metadata": {},
   "source": [
    "# Load park-data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "812b513d-29ee-4694-aee0-d5f69ece2f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------+--------------------------------------------------+------+------+----------+----------+-----------------------------+----------------------------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------------------+---------------------------------------+\n",
      "|AreaName         |AreaID|ParkName                                          |ParkID|Date  |StartTime |EndTime   |TotalTimeinminutesifavailable|ParkConditions                                                  |OtherAnimalSightings                                                      |Litter                                                           |Temperature&Weather                    |\n",
      "+-----------------+------+--------------------------------------------------+------+------+----------+----------+-----------------------------+----------------------------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------------------+---------------------------------------+\n",
      "|UPPER MANHATTAN  |A     |Fort Tryon Park                                   |1.0   |3/1/20|3:14:00 PM|4:05:00 PM|51                           |Busy                                                            |Humans, Dogs, Pigeons, Cardinals                                          |Some                                                             |43 degrees, sunny                      |\n",
      "|UPPER MANHATTAN  |A     |J. Hood Wright Park                               |2.0   |3/1/20|3:30:00 PM|4:00:00 PM|30                           |Calm                                                            |Humans, Hawks, Dogs, Pigeons, Rat                                         |Some, in trees                                                   |cold, clear                            |\n",
      "|UPPER MANHATTAN  |A     |Highbridge Park                                   |3.0   |3/1/20|3:21:00 PM|4:15:00 PM|54                           |Calm, pick-up baseball game                                     |Humans, Dogs (3, all on leashes), Downy Woodpecker (2), Robins, Song Birds|Some, especially caught in wooded area in East, balloons in trees|43 degrees                             |\n",
      "|UPPER MANHATTAN  |A     |St. Nicholas Park                                 |4.0   |3/1/20|3:15:00 PM|3:45:00 PM|30                           |Calm                                                            |Humans, Dogs                                                              |Some, backside of park                                           |43 degrees, clear                      |\n",
      "|UPPER MANHATTAN  |A     |Riverside Park (section near Grant Memorial)      |5.0   |3/1/20|3:15:00 PM|3:45:00 PM|30                           |Calm                                                            |Humans, Dogs                                                              |NULL                                                             |NULL                                   |\n",
      "|UPPER MANHATTAN  |A     |Marcus Garvey Park                                |6.0   |3/1/20|3:45:00 PM|4:15:00 PM|30                           |Calm, re: humans, but a hawk is certainly not a calming presence|Hawks, Dogs, Pigeons                                                      |Abundant                                                         |42 degrees, clear                      |\n",
      "|CENTRAL MANHATTAN|B     |Madison Square Park                               |7.0   |3/1/20|2:30:00 PM|3:50:00 PM|80                           |Busy                                                            |Humans, Dogs, Pigeons                                                     |NULL                                                             |43 degrees, sunny                      |\n",
      "|CENTRAL MANHATTAN|B     |Union Square Park                                 |8.0   |3/1/20|3:15:00 PM|3:45:00 PM|30                           |Busy                                                            |Humans, Dogs, Pigeons                                                     |NULL                                                             |40 degrees, sunny                      |\n",
      "|CENTRAL MANHATTAN|B     |Stuyvesant Square Park                            |9.0   |3/1/20|3:00:00 PM|4:00:00 PM|60                           |Calm, 20Š—–30 ppl on each side                                  |Humans, Dogs, Sparrows                                                    |Some                                                             |45 degrees, sunny                      |\n",
      "|CENTRAL MANHATTAN|B     |Washington Square Park                            |10.0  |3/1/20|3:20:00 PM|4:00:00 PM|40                           |Busy                                                            |Humans, Dogs                                                              |None                                                             |45 degrees, sunny with shade spots     |\n",
      "|CENTRAL MANHATTAN|B     |Tompkins Square Park                              |11.0  |3/1/20|3:15:00 PM|3:45:00 PM|30                           |NULL                                                            |NULL                                                                      |NULL                                                             |NULL                                   |\n",
      "|CENTRAL MANHATTAN|B     |John V. Lindsay East River Park                   |12.0  |3/1/20|3:01:00 PM|3:45:00 PM|44                           |Calm                                                            |Humans (Joggers, Bikers), Dogs                                            |NULL                                                             |windy, clear                           |\n",
      "|LOWER MANHATTAN  |C     |Sara D. Roosevelt Park (Section Above Delancey St)|13.1  |3/1/20|3:30:00 PM|4:00:00 PM|30                           |Busy                                                            |Humans, Dogs (Gray)                                                       |Some                                                             |44 degrees, sunny                      |\n",
      "|LOWER MANHATTAN  |C     |Sara D. Roosevelt Park (Section Below Delancey St)|13.2  |3/1/20|3:30:00 PM|4:00:00 PM|30                           |Busy                                                            |Humans, Pigeons                                                           |Some                                                             |43 degrees, sunny                      |\n",
      "|LOWER MANHATTAN  |C     |Seward Park                                       |14.0  |3/1/20|3:25:00 PM|3:55:00 PM|30                           |Busy                                                            |Humans, Pigeons                                                           |Some                                                             |40 degrees, sunny                      |\n",
      "|LOWER MANHATTAN  |C     |Corlears Hook Park                                |15.0  |3/1/20|3:35:00 PM|4:15:00 PM|40                           |Calm                                                            |Humans, Dogs, Pigeons                                                     |Some, mostly in trees                                            |48 degrees, sunny                      |\n",
      "|LOWER MANHATTAN  |C     |Columbus Park                                     |16.0  |3/1/20|3:47:00 PM|4:38:00 PM|51                           |Busy                                                            |Humans, Dogs, Pigeons                                                     |None                                                             |42 degrees, windy, dry, clear          |\n",
      "|LOWER MANHATTAN  |C     |Thomas Paine Park                                 |17.0  |3/1/20|3:35:00 PM|3:45:00 PM|10                           |Calm                                                            |Humans, Dogs, Pigeons                                                     |None                                                             |42 degrees, windy, dry, clear          |\n",
      "|LOWER MANHATTAN  |C     |Teardrop Park                                     |18.0  |3/1/20|3:37:00 PM|4:00:00 PM|23                           |NULL                                                            |Humans, Dogs, Fish in Pond, Geese, Half-eaten Dead Rat                    |Some                                                             |43 degrees, sunny, with 20-30 mph gusts|\n",
      "|LOWER MANHATTAN  |C     |City Hall Park                                    |19.0  |3/1/20|3:34:00 PM|4:04:00 PM|30                           |Calm                                                            |Humans, Pigeons, Cat                                                      |None                                                             |44 degrees, sunny                      |\n",
      "+-----------------+------+--------------------------------------------------+------+------+----------+----------+-----------------------------+----------------------------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------------------+---------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load data from the CSV file\n",
    "df_park = spark.read.csv(\"source/park-data.csv\", header=True, inferSchema=True, encoding=\"UTF-8\")\n",
    "\n",
    "# Rename columns by removing whitespace\n",
    "for col_name in df_park.columns:\n",
    "    new_col_name = col_name.replace(\" \", \"\")\n",
    "    df_park = df_park.withColumnRenamed(col_name, new_col_name)\n",
    "\n",
    "def clean_column_names(df):\n",
    "    for col_name in df.columns:\n",
    "        # Remove parentheses and commas from column names\n",
    "        new_col_name = col_name.replace(\"(\", \"\").replace(\")\", \"\").replace(\",\", \"\")\n",
    "        df = df.withColumnRenamed(col_name, new_col_name)\n",
    "    return df\n",
    "\n",
    "# Apply the function to clean column names\n",
    "df_park = clean_column_names(df_park)\n",
    "\n",
    "# Show the result\n",
    "df_park.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c06e29-f9c5-433a-9a24-c1763f36a388",
   "metadata": {},
   "source": [
    "### Preprocessing park-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71a9dc3d-142d-4cbb-80d1-e10e9b06e89a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------+-------------------------------------------------+------+----------+---------+--------+-----------------------------+----------------------------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------------------+--------------------------------------+\n",
      "|AreaName         |AreaID|ParkName                                         |ParkID|Date      |StartTime|EndTime |TotalTimeinminutesifavailable|ParkConditions                                                  |OtherAnimalSightings                                                      |Litter                                                           |Temperature&Weather                   |\n",
      "+-----------------+------+-------------------------------------------------+------+----------+---------+--------+-----------------------------+----------------------------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------------------+--------------------------------------+\n",
      "|UPPER MANHATTAN  |A     |Fort Tryon Park                                  |1.0   |03/01/2020|15:14:00 |16:05:00|51                           |Busy                                                            |Humans, Dogs, Pigeons, Cardinals                                          |Some                                                             |43 degrees, sunny                     |\n",
      "|UPPER MANHATTAN  |A     |J Hood Wright Park                               |2.0   |03/01/2020|15:30:00 |16:00:00|30                           |Calm                                                            |Humans, Hawks, Dogs, Pigeons, Rat                                         |Some, in trees                                                   |cold, clear                           |\n",
      "|UPPER MANHATTAN  |A     |Highbridge Park                                  |3.0   |03/01/2020|15:21:00 |16:15:00|54                           |Calm, pickup baseball game                                      |Humans, Dogs (3, all on leashes), Downy Woodpecker (2), Robins, Song Birds|Some, especially caught in wooded area in East, balloons in trees|43 degrees                            |\n",
      "|UPPER MANHATTAN  |A     |St Nicholas Park                                 |4.0   |03/01/2020|15:15:00 |15:45:00|30                           |Calm                                                            |Humans, Dogs                                                              |Some, backside of park                                           |43 degrees, clear                     |\n",
      "|UPPER MANHATTAN  |A     |Riverside Park (section near Grant Memorial)     |5.0   |03/01/2020|15:15:00 |15:45:00|30                           |Calm                                                            |Humans, Dogs                                                              |ND                                                               |ND                                    |\n",
      "|UPPER MANHATTAN  |A     |Marcus Garvey Park                               |6.0   |03/01/2020|15:45:00 |16:15:00|30                           |Calm, re: humans, but a hawk is certainly not a calming presence|Hawks, Dogs, Pigeons                                                      |Abundant                                                         |42 degrees, clear                     |\n",
      "|CENTRAL MANHATTAN|B     |Madison Square Park                              |7.0   |03/01/2020|14:30:00 |15:50:00|80                           |Busy                                                            |Humans, Dogs, Pigeons                                                     |ND                                                               |43 degrees, sunny                     |\n",
      "|CENTRAL MANHATTAN|B     |Union Square Park                                |8.0   |03/01/2020|15:15:00 |15:45:00|30                           |Busy                                                            |Humans, Dogs, Pigeons                                                     |ND                                                               |40 degrees, sunny                     |\n",
      "|CENTRAL MANHATTAN|B     |Stuyvesant Square Park                           |9.0   |03/01/2020|15:00:00 |16:00:00|60                           |Calm, 2030 ppl on each side                                     |Humans, Dogs, Sparrows                                                    |Some                                                             |45 degrees, sunny                     |\n",
      "|CENTRAL MANHATTAN|B     |Washington Square Park                           |10.0  |03/01/2020|15:20:00 |16:00:00|40                           |Busy                                                            |Humans, Dogs                                                              |None                                                             |45 degrees, sunny with shade spots    |\n",
      "|CENTRAL MANHATTAN|B     |Tompkins Square Park                             |11.0  |03/01/2020|15:15:00 |15:45:00|30                           |ND                                                              |ND                                                                        |ND                                                               |ND                                    |\n",
      "|CENTRAL MANHATTAN|B     |John V Lindsay East River Park                   |12.0  |03/01/2020|15:01:00 |15:45:00|44                           |Calm                                                            |Humans (Joggers, Bikers), Dogs                                            |ND                                                               |windy, clear                          |\n",
      "|LOWER MANHATTAN  |C     |Sara D Roosevelt Park (Section Above Delancey St)|13.1  |03/01/2020|15:30:00 |16:00:00|30                           |Busy                                                            |Humans, Dogs (Gray)                                                       |Some                                                             |44 degrees, sunny                     |\n",
      "|LOWER MANHATTAN  |C     |Sara D Roosevelt Park (Section Below Delancey St)|13.2  |03/01/2020|15:30:00 |16:00:00|30                           |Busy                                                            |Humans, Pigeons                                                           |Some                                                             |43 degrees, sunny                     |\n",
      "|LOWER MANHATTAN  |C     |Seward Park                                      |14.0  |03/01/2020|15:25:00 |15:55:00|30                           |Busy                                                            |Humans, Pigeons                                                           |Some                                                             |40 degrees, sunny                     |\n",
      "|LOWER MANHATTAN  |C     |Corlears Hook Park                               |15.0  |03/01/2020|15:35:00 |16:15:00|40                           |Calm                                                            |Humans, Dogs, Pigeons                                                     |Some, mostly in trees                                            |48 degrees, sunny                     |\n",
      "|LOWER MANHATTAN  |C     |Columbus Park                                    |16.0  |03/01/2020|15:47:00 |16:38:00|51                           |Busy                                                            |Humans, Dogs, Pigeons                                                     |None                                                             |42 degrees, windy, dry, clear         |\n",
      "|LOWER MANHATTAN  |C     |Thomas Paine Park                                |17.0  |03/01/2020|15:35:00 |15:45:00|10                           |Calm                                                            |Humans, Dogs, Pigeons                                                     |None                                                             |42 degrees, windy, dry, clear         |\n",
      "|LOWER MANHATTAN  |C     |Teardrop Park                                    |18.0  |03/01/2020|15:37:00 |16:00:00|23                           |ND                                                              |Humans, Dogs, Fish in Pond, Geese, Halfeaten Dead Rat                     |Some                                                             |43 degrees, sunny, with 2030 mph gusts|\n",
      "|LOWER MANHATTAN  |C     |City Hall Park                                   |19.0  |03/01/2020|15:34:00 |16:04:00|30                           |Calm                                                            |Humans, Pigeons, Cat                                                      |None                                                             |44 degrees, sunny                     |\n",
      "+-----------------+------+-------------------------------------------------+------+----------+---------+--------+-----------------------------+----------------------------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------------------+--------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "# AreaName #\n",
    "############\n",
    "# Clean the \"AreaName\" column by replacing special characters and trimming whitespace\n",
    "df_park = df_park.withColumn(\n",
    "    \"AreaName\",\n",
    "    trim(regexp_replace(col(\"AreaName\"), \"[^a-zA-Z0-9\\s#(),:]\", \"\"))\n",
    ")\n",
    "\n",
    "# Replace empty and NULL values with \"ND\"\n",
    "df_park = df_park.withColumn(\n",
    "    \"AreaName\",\n",
    "    when((col(\"AreaName\") == \"\") | (col(\"AreaName\").isNull()), \"ND\").otherwise(col(\"AreaName\"))\n",
    ")\n",
    "\n",
    "\n",
    "############\n",
    "#  AreaID  #\n",
    "############\n",
    "# Clean the \"AreaID\" column by replacing special characters and trimming whitespace\n",
    "df_park = df_park.withColumn(\n",
    "    \"AreaID\",\n",
    "    trim(regexp_replace(col(\"AreaID\"), \"[^a-zA-Z0-9\\s#(),:]\", \"\"))\n",
    ")\n",
    "\n",
    "# Replace empty and NULL values with \"ND\"\n",
    "df_park = df_park.withColumn(\n",
    "    \"AreaID\",\n",
    "    when((col(\"AreaID\") == \"\") | (col(\"AreaID\").isNull()), \"ND\").otherwise(col(\"AreaID\"))\n",
    ")\n",
    "\n",
    "\n",
    "############\n",
    "# ParkName #\n",
    "############\n",
    "# Clean the \"ParkName\" column by replacing special characters and trimming whitespace\n",
    "df_park = df_park.withColumn(\n",
    "    \"ParkName\",\n",
    "    trim(regexp_replace(col(\"ParkName\"), \"[^a-zA-Z0-9\\s#(),:]\", \"\"))\n",
    ")\n",
    "\n",
    "# Replace empty and NULL values with \"ND\"\n",
    "df_park = df_park.withColumn(\n",
    "    \"ParkName\",\n",
    "    when((col(\"ParkName\") == \"\") | (col(\"ParkName\").isNull()), \"ND\").otherwise(col(\"ParkName\"))\n",
    ")\n",
    "\n",
    "\n",
    "########\n",
    "# Date # \n",
    "########\n",
    "# Assuming the column containing dates is named \"date_column\"\n",
    "df_park = df_park.withColumn(\"Date\", date_format(to_date(\"Date\", \"d/M/yy\"), \"dd/MM/yyyy\"))\n",
    "\n",
    "########\n",
    "# Time # \n",
    "########\n",
    "# Format time columns\n",
    "df_park = df_park.withColumn(\"StartTime\", date_format(to_timestamp(\"StartTime\", \"h:mm:ss a\"), \"HH:mm:ss\"))\n",
    "df_park = df_park.withColumn(\"EndTime\", date_format(to_timestamp(\"EndTime\", \"h:mm:ss a\"), \"HH:mm:ss\"))\n",
    "\n",
    "\n",
    "#################################\n",
    "# TotalTimeinminutesifavailable #\n",
    "#################################\n",
    "\n",
    "# Clean the \"TotalTimeinminutesifavailable\" column by replacing special characters and trimming whitespace\n",
    "df_park = df_park.withColumn(\n",
    "    \"TotalTimeinminutesifavailable\",\n",
    "    trim(regexp_replace(col(\"TotalTimeinminutesifavailable\"), \"[^a-zA-Z0-9\\s#(),:]\", \"\"))\n",
    ")\n",
    "\n",
    "# Replace empty and NULL values in \"TotalTimeinminutesifavailable\"\n",
    "df_park = df_park.withColumn(\n",
    "    \"TotalTimeinminutesifavailable\",\n",
    "    when((col(\"TotalTimeinminutesifavailable\") == \"\") | (col(\"TotalTimeinminutesifavailable\").isNull()), \n",
    "         expr(\"datediff(EndTime, StartTime) * 24 * 60\")\n",
    "        ).otherwise(col(\"TotalTimeinminutesifavailable\"))\n",
    ")\n",
    "\n",
    "##################\n",
    "# ParkConditions #     \n",
    "##################\n",
    "\n",
    "# Clean the \"ParkConditions\" column by replacing special characters and trimming whitespace\n",
    "df_park = df_park.withColumn(\n",
    "    \"ParkConditions\",\n",
    "    trim(regexp_replace(col(\"ParkConditions\"), \"[^a-zA-Z0-9\\s#(),:]\", \"\"))\n",
    ")\n",
    "\n",
    "# Replace empty and NULL values with \"ND\"\n",
    "df_park = df_park.withColumn(\n",
    "    \"ParkConditions\",\n",
    "    when((col(\"ParkConditions\") == \"\") | (col(\"ParkConditions\").isNull()), \"ND\").otherwise(col(\"ParkConditions\"))\n",
    ")\n",
    "\n",
    "########################\n",
    "# OtherAnimalSightings #\n",
    "########################\n",
    "\n",
    "# Clean the \"OtherAnimalSightings\" column by replacing special characters and trimming whitespace\n",
    "df_park = df_park.withColumn(\n",
    "    \"OtherAnimalSightings\",\n",
    "    trim(regexp_replace(col(\"OtherAnimalSightings\"), \"[^a-zA-Z0-9\\s#(),:]\", \"\"))\n",
    ")\n",
    "\n",
    "# Replace empty and NULL values with \"ND\"\n",
    "df_park = df_park.withColumn(\n",
    "    \"OtherAnimalSightings\",\n",
    "    when((col(\"OtherAnimalSightings\") == \"\") | (col(\"OtherAnimalSightings\").isNull()), \"ND\").otherwise(col(\"OtherAnimalSightings\"))\n",
    ")\n",
    "\n",
    "\n",
    "##########\n",
    "# Litter #\n",
    "##########\n",
    "\n",
    "# Clean the \"Litter\" column by replacing special characters and trimming whitespace\n",
    "df_park = df_park.withColumn(\n",
    "    \"Litter\",\n",
    "    trim(regexp_replace(col(\"Litter\"), \"[^a-zA-Z0-9\\s#(),:]\", \"\"))\n",
    ")\n",
    "\n",
    "# Replace empty and NULL values with \"ND\"\n",
    "df_park = df_park.withColumn(\n",
    "    \"Litter\",\n",
    "    when((col(\"Litter\") == \"\") | (col(\"Litter\").isNull()), \"ND\").otherwise(col(\"Litter\"))\n",
    ")\n",
    "\n",
    "#######################\n",
    "# Temperature&Weather #\n",
    "#######################\n",
    "\n",
    "# Clean the \"Temperature&Weather\" column by replacing special characters and trimming whitespace\n",
    "df_park = df_park.withColumn(\n",
    "    \"Temperature&Weather\",\n",
    "    trim(regexp_replace(col(\"Temperature&Weather\"), \"[^a-zA-Z0-9\\s#(),:]\", \"\"))\n",
    ")\n",
    "\n",
    "# Replace empty and NULL values with \"ND\"\n",
    "df_park = df_park.withColumn(\n",
    "    \"Temperature&Weather\",\n",
    "    when((col(\"Temperature&Weather\") == \"\") | (col(\"Temperature&Weather\").isNull()), \"ND\").otherwise(col(\"Temperature&Weather\"))\n",
    ")\n",
    "\n",
    "\n",
    "# Show the result\n",
    "df_park.show(truncate=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7547fe-2454-4c5b-b478-e30985c8b429",
   "metadata": {},
   "source": [
    "# Load squirrel-data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9d4de8c-639e-496e-8359-a61acff03f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+---------------+--------------------+----------+------------+-----------------------+----------------+----------------------------------+----------------------+------------------------+-------------------------+---------------------------+\n",
      "|ParkID|SquirrelID|PrimaryFurColor|HighlightsinFurColor|ColorNotes|Location    |AboveGroundHeightinFeet|SpecificLocation|Activities                        |InteractionswithHumans|OtherNotesorObservations|SquirrelLatitudeDD.DDDDDD|SquirrelLongitude-DD.DDDDDD|\n",
      "+------+----------+---------------+--------------------+----------+------------+-----------------------+----------------+----------------------------------+----------------------+------------------------+-------------------------+---------------------------+\n",
      "|1     |A-01-01   |Gray           |White               |NULL      |Ground Plane|NULL                   |NULL            |Foraging                          |Indifferent           |NULL                    |40.85941                 |-73.933936                 |\n",
      "|1     |A-01-02   |Gray           |White               |NULL      |Ground Plane|NULL                   |NULL            |Foraging                          |Indifferent           |Looks skinny            |40.859436                |-73.933937                 |\n",
      "|1     |A-01-03   |Gray           |White               |NULL      |Ground Plane|NULL                   |NULL            |Eating, Digging something         |Indifferent           |NULL                    |40.859416                |-73.933894                 |\n",
      "|1     |A-01-04   |Gray           |White               |NULL      |Ground Plane|NULL                   |NULL            |Running                           |Indifferent           |NULL                    |40.859418                |-73.933895                 |\n",
      "|1     |A-01-05   |Gray           |Cinnamon            |NULL      |Ground Plane|NULL                   |NULL            |Running, Eating                   |Indifferent           |She left food           |40.859493                |-73.93359                  |\n",
      "|1     |A-01-06   |Gray           |Cinnamon            |NULL      |Ground Plane|NULL                   |NULL            |Climbing                          |Indifferent           |NULL                    |40.860825                |-73.932871                 |\n",
      "|1     |A-01-07   |Gray           |White               |NULL      |Ground Plane|NULL                   |NULL            |Foraging                          |Indifferent           |NULL                    |40.860225                |-73.933143                 |\n",
      "|1     |A-01-08   |Black          |Gray                |NULL      |Above Ground|10                     |NULL            |Climbing                          |Runs From             |NULL                    |40.859965                |-73.933412                 |\n",
      "|1     |A-01-09   |Gray           |White               |NULL      |Ground Plane|NULL                   |NULL            |Foraging                          |Indifferent           |NULL                    |40.859892                |-73.933326                 |\n",
      "|1     |A-01-10   |Gray           |White               |NULL      |Ground Plane|NULL                   |NULL            |Eating, Digging                   |Indifferent           |NULL                    |40.859636                |-73.933717                 |\n",
      "|1     |A-01-11   |Gray           |Black               |NULL      |Ground Plane|NULL                   |NULL            |Eating, Digging                   |Indifferent           |was intimidated by a dog|40.859576                |-73.933738                 |\n",
      "|1     |A-01-12   |Gray           |White               |NULL      |Ground Plane|NULL                   |NULL            |Running                           |Runs From             |NULL                    |40.859989                |-73.934544                 |\n",
      "|2     |A-02-01   |Gray           |Gray                |NULL      |Ground Plane|NULL                   |NULL            |Running                           |Indifferent           |NULL                    |40.845749                |-73.9407                   |\n",
      "|2     |A-02-02   |Gray           |Cinnamon            |NULL      |Above Ground|2                      |NULL            |Foraging                          |Indifferent           |NULL                    |40.845875                |-73.940808                 |\n",
      "|2     |A-02-03   |Gray           |Cinnamon            |NULL      |Ground Plane|NULL                   |NULL            |Foraging                          |NULL                  |NULL                    |40.845875                |-73.940808                 |\n",
      "|2     |A-02-04   |Gray           |Cinnamon            |NULL      |Ground Plane|NULL                   |NULL            |Running                           |Indifferent           |NULL                    |40.846088                |-73.940613                 |\n",
      "|2     |A-02-05   |Gray           |Cinnamon            |NULL      |Ground Plane|NULL                   |NULL            |Running                           |Runs From             |NULL                    |40.846088                |-73.940613                 |\n",
      "|2     |A-02-06   |Gray           |Cinnamon            |NULL      |Ground Plane|NULL                   |NULL            |Foraging                          |Indifferent           |NULL                    |40.846088                |-73.940613                 |\n",
      "|2     |A-02-07   |Gray           |Gray                |NULL      |Ground Plane|NULL                   |NULL            |NULL                              |Runs From             |NULL                    |40.846222                |-73.94094                  |\n",
      "|2     |A-02-08   |Gray           |Cinnamon            |NULL      |Ground Plane|NULL                   |NULL            |Foraging, Nesting/gathering leaves|Indifferent           |NULL                    |40.846222                |-73.94094                  |\n",
      "+------+----------+---------------+--------------------+----------+------------+-----------------------+----------------+----------------------------------+----------------------+------------------------+-------------------------+---------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load data from the CSV file into a DataFrame\n",
    "df_squirrel = spark.read.csv(\"source/squirrel-data.csv\", header=True, inferSchema=True, encoding=\"UTF-8\")\n",
    "\n",
    "# Rename columns by removing whitespace\n",
    "for col_name in df_squirrel.columns:\n",
    "    new_col_name = col_name.replace(\" \", \"\")\n",
    "    df_squirrel = df_squirrel.withColumnRenamed(col_name, new_col_name)\n",
    "\n",
    "def clean_column_names(df):\n",
    "    # Function to clean column names by removing parentheses and commas\n",
    "    for col_name in df.columns:\n",
    "        new_col_name = col_name.replace(\"(\", \"\").replace(\")\", \"\").replace(\",\", \"\")\n",
    "        df = df.withColumnRenamed(col_name, new_col_name)\n",
    "    return df\n",
    "\n",
    "# Apply the function to clean column names\n",
    "df_squirrel = clean_column_names(df_squirrel)\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "df_squirrel.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3a3af7-2061-4d87-a9a0-509042ceb665",
   "metadata": {},
   "source": [
    "# STAGING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545053ae-4332-4d7e-8e02-186754ec9627",
   "metadata": {},
   "source": [
    "### Preprocessing squirrel-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4711c1d3-30ad-44cd-b9f0-d4367fbf3771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+---------------+--------------------+----------+------------+----------------+----------------------------------+----------------------+------------------------+-------------------------+---------------------------+---------------+---------------+\n",
      "|ParkID|SquirrelID|PrimaryFurColor|HighlightsinFurColor|ColorNotes|Location    |SpecificLocation|Activities                        |InteractionswithHumans|OtherNotesorObservations|SquirrelLatitudeDD.DDDDDD|SquirrelLongitude-DD.DDDDDD|Min_Height_Feet|Max_Height_Feet|\n",
      "+------+----------+---------------+--------------------+----------+------------+----------------+----------------------------------+----------------------+------------------------+-------------------------+---------------------------+---------------+---------------+\n",
      "|1     |A-01-01   |Gray           |White               |ND        |Ground Plane|ND              |Foraging                          |Indifferent           |ND                      |40.85941                 |-73.933936                 |0              |0              |\n",
      "|1     |A-01-02   |Gray           |White               |ND        |Ground Plane|ND              |Foraging                          |Indifferent           |Looks skinny            |40.859436                |-73.933937                 |0              |0              |\n",
      "|1     |A-01-03   |Gray           |White               |ND        |Ground Plane|ND              |Eating, Digging something         |Indifferent           |ND                      |40.859416                |-73.933894                 |0              |0              |\n",
      "|1     |A-01-04   |Gray           |White               |ND        |Ground Plane|ND              |Running                           |Indifferent           |ND                      |40.859418                |-73.933895                 |0              |0              |\n",
      "|1     |A-01-05   |Gray           |Cinnamon            |ND        |Ground Plane|ND              |Running, Eating                   |Indifferent           |She left food           |40.859493                |-73.93359                  |0              |0              |\n",
      "|1     |A-01-06   |Gray           |Cinnamon            |ND        |Ground Plane|ND              |Climbing                          |Indifferent           |ND                      |40.860825                |-73.932871                 |0              |0              |\n",
      "|1     |A-01-07   |Gray           |White               |ND        |Ground Plane|ND              |Foraging                          |Indifferent           |ND                      |40.860225                |-73.933143                 |0              |0              |\n",
      "|1     |A-01-08   |Black          |Gray                |ND        |Above Ground|ND              |Climbing                          |Runs From             |ND                      |40.859965                |-73.933412                 |10             |10             |\n",
      "|1     |A-01-09   |Gray           |White               |ND        |Ground Plane|ND              |Foraging                          |Indifferent           |ND                      |40.859892                |-73.933326                 |0              |0              |\n",
      "|1     |A-01-10   |Gray           |White               |ND        |Ground Plane|ND              |Eating, Digging                   |Indifferent           |ND                      |40.859636                |-73.933717                 |0              |0              |\n",
      "|1     |A-01-11   |Gray           |Black               |ND        |Ground Plane|ND              |Eating, Digging                   |Indifferent           |was intimidated by a dog|40.859576                |-73.933738                 |0              |0              |\n",
      "|1     |A-01-12   |Gray           |White               |ND        |Ground Plane|ND              |Running                           |Runs From             |ND                      |40.859989                |-73.934544                 |0              |0              |\n",
      "|2     |A-02-01   |Gray           |Gray                |ND        |Ground Plane|ND              |Running                           |Indifferent           |ND                      |40.845749                |-73.9407                   |0              |0              |\n",
      "|2     |A-02-02   |Gray           |Cinnamon            |ND        |Above Ground|ND              |Foraging                          |Indifferent           |ND                      |40.845875                |-73.940808                 |2              |2              |\n",
      "|2     |A-02-03   |Gray           |Cinnamon            |ND        |Ground Plane|ND              |Foraging                          |ND                    |ND                      |40.845875                |-73.940808                 |0              |0              |\n",
      "|2     |A-02-04   |Gray           |Cinnamon            |ND        |Ground Plane|ND              |Running                           |Indifferent           |ND                      |40.846088                |-73.940613                 |0              |0              |\n",
      "|2     |A-02-05   |Gray           |Cinnamon            |ND        |Ground Plane|ND              |Running                           |Runs From             |ND                      |40.846088                |-73.940613                 |0              |0              |\n",
      "|2     |A-02-06   |Gray           |Cinnamon            |ND        |Ground Plane|ND              |Foraging                          |Indifferent           |ND                      |40.846088                |-73.940613                 |0              |0              |\n",
      "|2     |A-02-07   |Gray           |Gray                |ND        |Ground Plane|ND              |ND                                |Runs From             |ND                      |40.846222                |-73.94094                  |0              |0              |\n",
      "|2     |A-02-08   |Gray           |Cinnamon            |ND        |Ground Plane|ND              |Foraging, Nesting/gathering leaves|Indifferent           |ND                      |40.846222                |-73.94094                  |0              |0              |\n",
      "+------+----------+---------------+--------------------+----------+------------+----------------+----------------------------------+----------------------+------------------------+-------------------------+---------------------------+---------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assigning the DataFrame df_squirrel to squirrel_data\n",
    "squirrel_data = df_squirrel\n",
    "\n",
    "###################\n",
    "# PrimaryFurColor #\n",
    "###################\n",
    "# Clean the \"PrimaryFurColor\" column by replacing special characters and trimming whitespace\n",
    "squirrel_data = squirrel_data.withColumn(\n",
    "    \"PrimaryFurColor\",\n",
    "    trim(regexp_replace(col(\"PrimaryFurColor\"), \"[^a-zA-Z0-9\\s#,]\", \"\"))\n",
    ")\n",
    "\n",
    "# Replace empty and NULL values with \"ND\"\n",
    "squirrel_data = squirrel_data.withColumn(\n",
    "    \"PrimaryFurColor\",\n",
    "    when((col(\"PrimaryFurColor\") == \"\") | (col(\"PrimaryFurColor\").isNull()), \"ND\").otherwise(col(\"PrimaryFurColor\"))\n",
    ")\n",
    "\n",
    "########################\n",
    "# HighlightsinFurColor #\n",
    "########################\n",
    "# Clean the \"HighlightsinFurColor\" column by replacing special characters and trimming whitespace\n",
    "squirrel_data = squirrel_data.withColumn(\n",
    "    \"HighlightsinFurColor\",\n",
    "    trim(regexp_replace(col(\"HighlightsinFurColor\"), \"[^a-zA-Z0-9\\s#,]\", \"\"))\n",
    ")\n",
    "\n",
    "# Replace empty and NULL values with \"ND\"\n",
    "squirrel_data = squirrel_data.withColumn(\n",
    "    \"HighlightsinFurColor\",\n",
    "    when((col(\"HighlightsinFurColor\") == \"\") | (col(\"HighlightsinFurColor\").isNull()), \"ND\").otherwise(col(\"HighlightsinFurColor\"))\n",
    ")\n",
    "\n",
    "##############\n",
    "# ColorNotes #\n",
    "##############\n",
    "# Clean the \"ColorNotes\" column by replacing special characters and trimming whitespace\n",
    "squirrel_data = squirrel_data.withColumn(\n",
    "    \"ColorNotes\",\n",
    "    trim(regexp_replace(col(\"ColorNotes\"), \"[^a-zA-Z0-9\\s#(),:]\", \"\"))\n",
    ")\n",
    "\n",
    "# Replace empty and NULL values with \"ND\"\n",
    "squirrel_data = squirrel_data.withColumn(\n",
    "    \"ColorNotes\",\n",
    "    when((col(\"ColorNotes\") == \"\") | (col(\"ColorNotes\").isNull()), \"ND\").otherwise(col(\"ColorNotes\"))\n",
    ")\n",
    "\n",
    "#################################\n",
    "# Above Ground (Height in Feet) #\n",
    "#################################\n",
    "# Clean the \"Above Ground (Height in Feet)\" column by replacing special characters\n",
    "squirrel_data = squirrel_data.withColumn(\n",
    "    \"AboveGroundHeightinFeet\",\n",
    "    regexp_replace(col(\"AboveGroundHeightinFeet\"), \"[^\\d\\s><]\", \",\")\n",
    ")\n",
    "\n",
    "# Replace empty and NULL values with \"0\"\n",
    "squirrel_data = squirrel_data.withColumn(\n",
    "    \"AboveGroundHeightinFeet\",\n",
    "    when((col(\"AboveGroundHeightinFeet\") == \"\") | (col(\"AboveGroundHeightinFeet\").isNull()), \"0\").otherwise(col(\"AboveGroundHeightinFeet\"))\n",
    ")\n",
    "\n",
    "# Split the column \"Above Ground (Height in Feet)\" into two columns: minimum and maximum\n",
    "squirrel_data = squirrel_data.withColumn(\n",
    "    \"Min_Height_Feet\",\n",
    "    when(col(\"AboveGroundHeightinFeet\").contains(\"<\"), 0).otherwise(col(\"AboveGroundHeightinFeet\"))\n",
    ")\n",
    "\n",
    "squirrel_data = squirrel_data.withColumn(\n",
    "    \"Max_Height_Feet\",\n",
    "    when(col(\"AboveGroundHeightinFeet\").contains(\"<\"), \n",
    "         split(col(\"AboveGroundHeightinFeet\"), \"<\")[1]).otherwise(col(\"AboveGroundHeightinFeet\"))\n",
    ")\n",
    "\n",
    "# Split each row into a list of words using comma as delimiter\n",
    "squirrel_data = squirrel_data.withColumn(\"Min_Height_List\", split(\"Min_Height_Feet\", \",\"))\n",
    "\n",
    "# Remove empty elements from the list\n",
    "squirrel_data = squirrel_data.withColumn(\n",
    "    \"Min_Height_List\",\n",
    "    array_remove(\"Min_Height_List\", \"\")\n",
    ")\n",
    "\n",
    "# Convert elements of the list to integers\n",
    "squirrel_data = squirrel_data.withColumn(\n",
    "    \"Min_Height_List\",\n",
    "    expr(\"transform(Min_Height_List, x -> CAST(x AS INT))\")\n",
    ")\n",
    "\n",
    "# Find the minimum in the list and store it in the column \"Min_Height\"\n",
    "squirrel_data = squirrel_data.withColumn(\n",
    "    \"Min_Height_Feet\",\n",
    "    expr(\"CAST(array_min(Min_Height_List) AS INT)\")\n",
    ")\n",
    "\n",
    "# Drop the column \"Min_Height_List\" if no longer needed\n",
    "squirrel_data = squirrel_data.drop(\"Min_Height_List\")\n",
    "\n",
    "# Split each row into a list of words using comma as delimiter\n",
    "squirrel_data = squirrel_data.withColumn(\"Max_Height_List\", split(\"Max_Height_Feet\", \",\"))\n",
    "\n",
    "# Remove empty elements from the list\n",
    "squirrel_data = squirrel_data.withColumn(\n",
    "    \"Max_Height_List\",\n",
    "    array_remove(\"Max_Height_List\", \"\")\n",
    ")\n",
    "\n",
    "# Convert elements of the list to integers\n",
    "squirrel_data = squirrel_data.withColumn(\n",
    "    \"Max_Height_List\",\n",
    "    expr(\"transform(Max_Height_List, x -> CAST(x AS INT))\")\n",
    ")\n",
    "\n",
    "# Find the minimum in the list and store it in the column \"Min_Height\"\n",
    "squirrel_data = squirrel_data.withColumn(\n",
    "    \"Max_Height_Feet\",\n",
    "    expr(\"CAST(array_max(Max_Height_List) AS INT)\")\n",
    ")\n",
    "\n",
    "# Drop the column \"Min_Height_List\" if no longer needed\n",
    "squirrel_data = squirrel_data.drop(\"Max_Height_List\")\n",
    "\n",
    "# Drop the column \"AboveGroundHeightinFeet\" if no longer needed\n",
    "squirrel_data = squirrel_data.drop(\"AboveGroundHeightinFeet\")\n",
    "\n",
    "#############\n",
    "#  Location #\n",
    "#############\n",
    "# Clean the \"Location\" column by replacing special characters and trimming whitespace\n",
    "squirrel_data = squirrel_data.withColumn(\n",
    "    \"Location\",\n",
    "    trim(regexp_replace(col(\"Location\"), \"[^a-zA-Z0-9\\s#(),:]\", \"\"))\n",
    ")\n",
    "\n",
    "# Replace empty and NULL values with \"ND\"\n",
    "squirrel_data = squirrel_data.withColumn(\n",
    "    \"Location\",\n",
    "    when((col(\"Location\") == \"\") | (col(\"Location\").isNull()), \"ND\").otherwise(col(\"Location\"))\n",
    ")\n",
    "\n",
    "#####################\n",
    "# Specific Location #\n",
    "#####################\n",
    "# Clean the \"Specific Location\" column by replacing special characters and trimming whitespace\n",
    "squirrel_data = squirrel_data.withColumn(\n",
    "    \"SpecificLocation\",\n",
    "    trim(regexp_replace(col(\"SpecificLocation\"), \"[^a-zA-Z0-9\\s#(),:]\", \"\"))\n",
    ")\n",
    "\n",
    "# Replace empty and NULL values with \"ND\"\n",
    "squirrel_data = squirrel_data.withColumn(\n",
    "    \"SpecificLocation\",\n",
    "    when((col(\"SpecificLocation\") == \"\") | (col(\"SpecificLocation\").isNull()), \"ND\").otherwise(col(\"SpecificLocation\"))\n",
    ")\n",
    "\n",
    "################\n",
    "# \"Activities\" #\n",
    "################\n",
    "# Clean the \"Activities\" column by replacing special characters\n",
    "squirrel_data = squirrel_data.withColumn(\n",
    "    \"Activities\",\n",
    "    trim(regexp_replace(col(\"Activities\"), \"[^a-zA-Z0-9\\s#,/?():]\", \" \"))\n",
    ")\n",
    "\n",
    "# Replace empty and NULL values with \"ND\"\n",
    "squirrel_data = squirrel_data.withColumn(\n",
    "    \"Activities\",\n",
    "    when((col(\"Activities\") == \"\") | (col(\"Activities\").isNull()), \"ND\").otherwise(col(\"Activities\"))\n",
    ")\n",
    "\n",
    "##########################\n",
    "# InteractionswithHumans #\n",
    "##########################\n",
    "# Clean the \"Activities\" column by replacing special characters\n",
    "squirrel_data = squirrel_data.withColumn(\n",
    "    \"InteractionswithHumans\",\n",
    "    trim(regexp_replace(col(\"InteractionswithHumans\"), \"[^a-zA-Z0-9\\s#,/?():]\", \" \"))\n",
    ")\n",
    "\n",
    "# Replace empty and NULL values with \"ND\"\n",
    "squirrel_data = squirrel_data.withColumn(\n",
    "    \"InteractionswithHumans\",\n",
    "    when((col(\"InteractionswithHumans\") == \"\") | (col(\"InteractionswithHumans\").isNull()), \"ND\").otherwise(col(\"InteractionswithHumans\"))\n",
    ")\n",
    "\n",
    "############################\n",
    "# OtherNotesorObservations #\n",
    "############################\n",
    "# Clean the \"Activities\" column by replacing special characters\n",
    "squirrel_data = squirrel_data.withColumn(\n",
    "    \"OtherNotesorObservations\",\n",
    "    trim(regexp_replace(col(\"OtherNotesorObservations\"), \"[^a-zA-Z0-9\\s#,/?():]\", \" \"))\n",
    ")\n",
    "\n",
    "# Replace empty and NULL values with \"ND\"\n",
    "squirrel_data = squirrel_data.withColumn(\n",
    "    \"OtherNotesorObservations\",\n",
    "    when((col(\"OtherNotesorObservations\") == \"\") | (col(\"OtherNotesorObservations\").isNull()), \"ND\").otherwise(col(\"OtherNotesorObservations\"))\n",
    ")\n",
    "\n",
    "# Show the results\n",
    "squirrel_data.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f4cf8f-556c-4340-99ad-d456ca8e152c",
   "metadata": {},
   "source": [
    "# RELATIONAL - PARK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3699abda-009c-4e82-bb01-f72176261e3b",
   "metadata": {},
   "source": [
    "## Areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3a9c8c6-8dc6-42f0-9304-14d6f99677ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-----------------+\n",
      "|AreaID|Area_ID|         AreaName|\n",
      "+------+-------+-----------------+\n",
      "|     1|      A|  UPPER MANHATTAN|\n",
      "|     2|      B|CENTRAL MANHATTAN|\n",
      "|     3|      C|  LOWER MANHATTAN|\n",
      "|     4|      D|         BROOKLYN|\n",
      "+------+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create an areas table, removing duplicates and renaming columns\n",
    "# Selecting only \"AreaID\" and \"AreaName\" columns and removing duplicates\n",
    "Areas = df_park.select(\"AreaID\", \"AreaName\").distinct()\n",
    "\n",
    "# Rename the 'AreaID' column to 'Area_ID'\n",
    "Areas = Areas.withColumnRenamed(\"AreaID\", \"Area_ID\")\n",
    "\n",
    "# Sort by Area_ID in ascending order\n",
    "Areas = Areas.orderBy(\"Area_ID\")\n",
    "\n",
    "# Create a new column \"ParkStatusID\" with unique identifiers starting from 1\n",
    "# Assign unique IDs to each row using monotonically_increasing_id() function\n",
    "Areas = Areas.withColumn(\"AreaID\", monotonically_increasing_id() + 1)\n",
    "\n",
    "# Select the columns in the desired order\n",
    "Areas = Areas.select(\"AreaID\", \"Area_ID\", \"AreaName\")\n",
    "\n",
    "# Show the resulting areas table\n",
    "Areas.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29679a28-00a4-4193-baa3-f7c115c39aea",
   "metadata": {},
   "source": [
    "### Areas | Table Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c559fc9-02c6-4c13-9854-370515eea9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-----------------+\n",
      "|AreaID|Area_ID|         AreaName|\n",
      "+------+-------+-----------------+\n",
      "|     1|      A|  UPPER MANHATTAN|\n",
      "|     2|      B|CENTRAL MANHATTAN|\n",
      "|     3|      C|  LOWER MANHATTAN|\n",
      "|     4|      D|         BROOKLYN|\n",
      "+------+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create or replace a temporary view from the DataFrame \n",
    "Areas.createOrReplaceTempView(\"View_Areas\")\n",
    "\n",
    "# Define the name of the table containing park conditions\n",
    "table_name = \"areas\"\n",
    "\n",
    "# SQL query to retrieve the maximum ParkConditionID from the database\n",
    "max_cond_sql = \"\"\" SELECT COALESCE(MAX(AreaID), 0) AS max_table_cond_id \n",
    "                   FROM View_table_db\"\"\"\n",
    "\n",
    "# SQL query to identify common rows and add new ones if needed\n",
    "common_rows_sql = \"\"\"\n",
    "                        SELECT\n",
    "                            b.AreaID,\n",
    "                            b.Area_ID,\n",
    "                            b.AreaName\n",
    "                        FROM View_table_db b\n",
    "                        UNION ALL\n",
    "                        SELECT\n",
    "                            {max_table_cond_id} + ROW_NUMBER() OVER (ORDER BY a.AreaName) AS AreaID,\n",
    "                            a.Area_ID,\n",
    "                            a.AreaName\n",
    "                        FROM View_Areas a\n",
    "                        LEFT JOIN View_table_db b ON trim(a.AreaName) = trim(b.AreaName) AND\n",
    "                                                     a.Area_ID        = b.Area_ID\n",
    "                                                    \n",
    "                        WHERE b.AreaID IS NULL\n",
    "            \"\"\"\n",
    "\n",
    "# Call the function to update park conditions\n",
    "# The function update_table_db updates the areas table in the database\n",
    "Areas = update_table_db(spark, jdbc_url, connection_properties, table_name, max_cond_sql, common_rows_sql, Areas)\n",
    "\n",
    "# Create or replace a temporary view from the updated DataFrame\n",
    "Areas.createOrReplaceTempView(\"View_Areas\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95d65a9-461e-4001-94f9-6c60e099a98a",
   "metadata": {},
   "source": [
    "## Parks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "459239e2-1700-42f4-ba49-78f57d5b19dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant columns from the DataFrame\n",
    "Parks = df_park.select(\"ParkID\", \"AreaID\", \"ParkName\")\n",
    "\n",
    "# Remove everything between parentheses in the \"Park Name\" column\n",
    "Parks = Parks.withColumn(\"ParkName\", regexp_replace(col(\"ParkName\"), \"\\\\s*\\\\(.*?\\\\)\\\\s*\", \"\"))\n",
    "\n",
    "# Convert values in the \"Park ID\" column to integers\n",
    "Parks = Parks.withColumn(\"ParkID\", Parks[\"ParkID\"].cast(IntegerType()))\n",
    "\n",
    "# Perform distinct operation on the resulting table\n",
    "Parks = Parks.distinct()\n",
    "\n",
    "# Sort by the \"Park ID\" column\n",
    "Parks = Parks.orderBy(\"ParkID\")\n",
    "\n",
    "# Create or replace a temporary view from the DataFrame \n",
    "Parks.createOrReplaceTempView(\"View_tmpParks\")\n",
    "\n",
    "# SQL query to join with the areas table and select relevant columns\n",
    "Parks = spark.sql(\"\"\"\n",
    "    SELECT a.ParkID, b.AreaID, a.ParkName\n",
    "    FROM View_tmpParks a LEFT JOIN View_Areas b ON a.AreaID = b.Area_ID\n",
    "    ORDER BY a.ParkID\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f655fb27-03b3-4a3f-8ea9-0197b7aeb1cd",
   "metadata": {},
   "source": [
    "### Parks | Table Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e812d9d2-8603-4de2-8805-351b4cf77ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+--------------------+\n",
      "|ParkID|AreaID|            ParkName|\n",
      "+------+------+--------------------+\n",
      "|     1|     1|     Fort Tryon Park|\n",
      "|     2|     1|  J Hood Wright Park|\n",
      "|     3|     1|     Highbridge Park|\n",
      "|     4|     1|    St Nicholas Park|\n",
      "|     5|     1|      Riverside Park|\n",
      "|     6|     1|  Marcus Garvey Park|\n",
      "|     7|     2| Madison Square Park|\n",
      "|     8|     2|   Union Square Park|\n",
      "|     9|     2|Stuyvesant Square...|\n",
      "|    10|     2|Washington Square...|\n",
      "|    11|     2|Tompkins Square Park|\n",
      "|    12|     2|John V Lindsay Ea...|\n",
      "|    13|     3|Sara D Roosevelt ...|\n",
      "|    14|     3|         Seward Park|\n",
      "|    15|     3|  Corlears Hook Park|\n",
      "|    16|     3|       Columbus Park|\n",
      "|    17|     3|   Thomas Paine Park|\n",
      "|    18|     3|       Teardrop Park|\n",
      "|    19|     3|      City Hall Park|\n",
      "|    20|     3|        Battery Park|\n",
      "+------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create or replace a temporary view from the DataFrame \n",
    "Parks.createOrReplaceTempView(\"View_Parks_tmp\")\n",
    "\n",
    "# Define the name of the table containing park conditions\n",
    "table_name = \"parks\"\n",
    "\n",
    "# SQL query to retrieve the maximum ParkConditionID from the database\n",
    "max_cond_sql = \"\"\" SELECT COALESCE(MAX(ParkID), 0) AS max_table_cond_id \n",
    "                   FROM View_table_db\"\"\"\n",
    "\n",
    "# SQL query to identify common rows and add new ones if needed\n",
    "common_rows_sql = \"\"\"\n",
    "                        SELECT\n",
    "                            b.ParkID,\n",
    "                            b.AreaID,\n",
    "                            b.ParkName\n",
    "                        FROM View_table_db b\n",
    "                        UNION ALL\n",
    "                        SELECT\n",
    "                            {max_table_cond_id} + ROW_NUMBER() OVER (ORDER BY a.ParkName) AS ParkID,\n",
    "                            a.AreaID,\n",
    "                            a.ParkName\n",
    "                        FROM View_Parks_tmp a\n",
    "                        LEFT JOIN View_table_db b ON trim(a.ParkName) = trim(b.ParkName) AND\n",
    "                                                          a.AreaID    = b.AreaID\n",
    "                        WHERE b.ParkID IS NULL\n",
    "            \"\"\"\n",
    "# Call the function to update park conditions\n",
    "Parks = update_table_db(spark, jdbc_url, connection_properties, table_name, max_cond_sql, common_rows_sql, Parks)\n",
    "\n",
    "# Create or replace a temporary view from the DataFrame \n",
    "Parks.createOrReplaceTempView(\"View_Parks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca262b9-c543-4e21-93fd-ef86126cd308",
   "metadata": {},
   "source": [
    "## ParkSections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94cbaa86-6fcc-4432-8193-8b4f86523d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows containing the word \"section\" in the \"Park Name\" column (case-insensitive)\n",
    "ParkSections = df_park.filter(lower(df_park[\"ParkName\"]).contains(\"section\"))\n",
    "\n",
    "# Create a table of park sections, removing duplicates and renaming columns\n",
    "ParkSections = ParkSections.select(\"ParkID\", \"ParkName\")\n",
    "\n",
    "# Keep only what comes after the word \"section\" in the \"Park Name\" column (case-insensitive)\n",
    "ParkSections = ParkSections.withColumn(\"ParkName\", split(lower(ParkSections[\"ParkName\"]), \"section\")[1])\n",
    "\n",
    "# Remove the \")\" at the end of the text\n",
    "ParkSections = ParkSections.withColumn(\"ParkName\", regexp_replace(col(\"ParkName\"), \"\\\\)$\", \"\"))\n",
    "\n",
    "# Capitalize the first letter of each word\n",
    "ParkSections = ParkSections.withColumn(\"ParkName\", initcap(col(\"ParkName\")))\n",
    "\n",
    "# Create a new column containing only the integer part of \"Park ID\"\n",
    "ParkSections = ParkSections.withColumn(\"Park ID\", regexp_extract(col(\"ParkID\").cast(\"string\"), r\"\\d+\", 0))\n",
    "\n",
    "# Select columns in the desired order\n",
    "ParkSections = ParkSections.select(\"ParkID\", \"Park ID\", \"ParkName\")\n",
    "\n",
    "# Rename columns\n",
    "ParkSections = ParkSections.withColumnRenamed(\"ParkID\", \"SectionID\") \\\n",
    "                           .withColumnRenamed(\"Park ID\", \"ParkID\") \\\n",
    "                           .withColumnRenamed(\"ParkName\", \"ParkSectionName\")\n",
    "\n",
    "# Select only what comes after the dot in the \"SectionID\" column\n",
    "ParkSections = ParkSections.withColumn(\"SectionID\", split(col(\"SectionID\").cast(\"string\"), \"\\\\.\").getItem(1))\n",
    "\n",
    "# Create a new column \"ParkSectionID\" with unique identifiers starting from 1\n",
    "ParkSections = ParkSections.withColumn(\"ParkSectionID\", monotonically_increasing_id() + 1)\n",
    "\n",
    "# Select the desired columns\n",
    "ParkSections = ParkSections.select(\"ParkSectionID\", \"SectionID\", \"ParkID\", \"ParkSectionName\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e1509a-6b9d-4ced-afaf-03d1a8ab6d57",
   "metadata": {},
   "source": [
    "### ParkSections | Table Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b35f4f8d-6b2c-4a6a-b3cf-f2650179c419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------+---------+--------------------+\n",
      "|ParkSectionID|ParkID|SectionID|     ParkSectionName|\n",
      "+-------------+------+---------+--------------------+\n",
      "|            1|     5|        0| Near Grant Memorial|\n",
      "|            2|    13|        1|   Above Delancey St|\n",
      "|            3|    13|        2|   Below Delancey St|\n",
      "+-------------+------+---------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create or replace a temporary view from the DataFrame \n",
    "ParkSections.createOrReplaceTempView(\"View_ParkSections\")\n",
    "\n",
    "# Define the name of the table containing park conditions\n",
    "table_name = \"parksections\"\n",
    "\n",
    "# SQL query to retrieve the maximum ParkConditionID from the database\n",
    "max_cond_sql = \"\"\" SELECT COALESCE(MAX(ParkSectionID), 0) AS max_table_cond_id \n",
    "                   FROM View_table_db\"\"\"\n",
    "\n",
    "# SQL query to identify common rows and add new ones if needed\n",
    "common_rows_sql = \"\"\"\n",
    "                        SELECT\n",
    "                            b.ParkSectionID,\n",
    "                            b.ParkID,\n",
    "                            b.SectionID,\n",
    "                            b.ParkSectionName\n",
    "                        FROM View_table_db b\n",
    "                        UNION ALL\n",
    "                        SELECT\n",
    "                            {max_table_cond_id} + ROW_NUMBER() OVER (ORDER BY a.ParkSectionName) AS ParkSectionID,\n",
    "                            a.ParkID,\n",
    "                            a.SectionID,\n",
    "                            a.ParkSectionName\n",
    "                        FROM View_ParkSections a\n",
    "                        LEFT JOIN View_table_db b ON trim(a.ParkSectionName) = trim(b.ParkSectionName)\n",
    "                        WHERE b.ParkSectionID IS NULL\n",
    "            \"\"\"\n",
    "\n",
    "# Call the function to update park conditions\n",
    "ParkSections = update_table_db(spark, jdbc_url, connection_properties, table_name, max_cond_sql, common_rows_sql, ParkSections)\n",
    "\n",
    "# Create or replace a temporary view from the DataFrame \n",
    "ParkSections.createOrReplaceTempView(\"View_ParkSections\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c724d5bd-fbdc-43af-b1ee-662788df8049",
   "metadata": {},
   "source": [
    "## ParkConditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3d641f3-4356-4261-ade4-bc6991166ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the \"ParkConditions\" column from the DataFrame\n",
    "ParkConditions = df_park.select(\"ParkConditions\")\n",
    "\n",
    "# Fill null values in the \"Park Conditions\" column with \"ND\"\n",
    "ParkConditions = ParkConditions.withColumn(\"ParkConditions\", when(col(\"ParkConditions\").isNull(), \"ND\").otherwise(col(\"ParkConditions\")))\n",
    "\n",
    "# Remove everything that comes after the comma\n",
    "ParkConditions = ParkConditions.withColumn(\"ParkConditions\", split(col(\"ParkConditions\"), \",\")[0])\n",
    "\n",
    "# Perform group by operation on the \"Park Conditions\" column without aggregation\n",
    "ParkConditions = ParkConditions.groupBy(\"ParkConditions\").count().distinct()\n",
    "\n",
    "# Remove any quotes within the values\n",
    "ParkConditions = ParkConditions.withColumn(\"ParkConditions\", regexp_replace(col(\"ParkConditions\"), '\"', ''))\n",
    "\n",
    "# Sort the results in alphabetical order\n",
    "ParkConditions = ParkConditions.orderBy(\"ParkConditions\")\n",
    "\n",
    "# Create a new column \"ParkConditionID\" with unique identifiers starting from 1\n",
    "ParkConditions = ParkConditions.withColumn(\"ParkConditionID\", monotonically_increasing_id() + 1)\n",
    "\n",
    "# Rename the column to \"ParkConditionName\"\n",
    "ParkConditions = ParkConditions.withColumnRenamed(\"ParkConditions\", \"ParkConditionName\")\n",
    "\n",
    "# Reorder the columns to place \"ParkConditionID\" at the beginning\n",
    "ParkConditions = ParkConditions.select(\"ParkConditionID\", \"ParkConditionName\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d0799a-9142-4514-b2ac-21db8bfa6a99",
   "metadata": {},
   "source": [
    "### ParkConditions | Table Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa517aa5-a265-49a7-ab89-167d8a762003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------------+\n",
      "|ParkConditionID|ParkConditionName|\n",
      "+---------------+-----------------+\n",
      "|              1|             Busy|\n",
      "|              2|             Calm|\n",
      "|              3|       Cool  Hank|\n",
      "|              4|           Medium|\n",
      "|              5|               ND|\n",
      "+---------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create or replace a temporary view from the DataFrame \n",
    "ParkConditions.createOrReplaceTempView(\"View_ParkConditions\")\n",
    "\n",
    "# Define the name of the table containing park conditions\n",
    "table_name = \"parkconditions\"\n",
    "\n",
    "# SQL query to retrieve the maximum ParkConditionID from the database\n",
    "max_cond_sql = \"\"\" SELECT COALESCE(MAX(ParkConditionID), 0) AS max_table_cond_id \n",
    "                   FROM View_table_db\"\"\"\n",
    "\n",
    "# SQL query to identify common rows and add new ones if needed\n",
    "common_rows_sql = \"\"\"\n",
    "                        SELECT\n",
    "                            b.ParkConditionID,\n",
    "                            b.ParkConditionName\n",
    "                        FROM View_table_db b\n",
    "                        UNION ALL\n",
    "                        SELECT\n",
    "                            {max_table_cond_id} + ROW_NUMBER() OVER (ORDER BY a.ParkConditionName) AS ParkConditionID,\n",
    "                            a.ParkConditionName\n",
    "                        FROM View_ParkConditions a\n",
    "                        LEFT JOIN View_table_db b ON trim(a.ParkConditionName) = trim(b.ParkConditionName)\n",
    "                        WHERE b.ParkConditionID IS NULL\n",
    "            \"\"\"\n",
    "\n",
    "# Call the function to update park conditions\n",
    "ParkConditions = update_table_db(spark, jdbc_url, connection_properties, table_name, max_cond_sql, common_rows_sql, ParkConditions)\n",
    "\n",
    "# Create or replace a temporary view from the DataFrame \n",
    "ParkConditions.createOrReplaceTempView(\"View_ParkConditions\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9f946d-aec9-4bf1-b3fe-e2edace98ee5",
   "metadata": {},
   "source": [
    "## ParkLitters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6d32459-b010-4f26-ae98-e5d031420e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the \"Litter\" column from the DataFrame\n",
    "ParksLitters = df_park.select(\"Litter\")\n",
    "\n",
    "# Fill null values in the \"Litter\" column with \"ND\"\n",
    "ParkLitters = ParksLitters.withColumn(\"Litter\", when(col(\"Litter\").isNull(), \"ND\").otherwise(col(\"Litter\")))\n",
    "\n",
    "# Remove everything that comes after the comma\n",
    "ParkLitters = ParkLitters.withColumn(\"Litter\", split(col(\"Litter\"), \",\")[0])\n",
    "\n",
    "# Perform group by operation on the \"Litter\" column without aggregation\n",
    "ParkLitters = ParkLitters.groupBy(\"Litter\").count().distinct()\n",
    "\n",
    "# Remove any quotes within the values\n",
    "ParkLitters = ParkLitters.withColumn(\"Litter\", regexp_replace(col(\"Litter\"), '\"', ''))\n",
    "\n",
    "# Sort the results in alphabetical order\n",
    "ParkLitters = ParkLitters.orderBy(\"Litter\")\n",
    "\n",
    "# Create a new column \"ParkLitterID\" with unique identifiers starting from 1\n",
    "ParkLitters = ParkLitters.withColumn(\"ParkLitterID\", monotonically_increasing_id() + 1)\n",
    "\n",
    "# Reorder the columns to place \"ParkLitterID\" at the beginning\n",
    "ParkLitters = ParkLitters.select(\"ParkLitterID\", \"Litter\")\n",
    "\n",
    "# Rename the column to \"ParkLitterName\"\n",
    "ParkLitters = ParkLitters.withColumnRenamed(\"Litter\", \"ParkLitterName\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8319e49-bad6-426b-8052-d91b03b57f92",
   "metadata": {},
   "source": [
    "### ParkLitters | Table Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0aeb7bd0-3c80-4b8d-b82c-57730e3d7df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------+\n",
      "|ParkLitterID|ParkLitterName|\n",
      "+------------+--------------+\n",
      "|           1|      Abundant|\n",
      "|           2|            ND|\n",
      "|           3|          None|\n",
      "|           4|          Some|\n",
      "+------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create or replace a temporary view from the DataFrame \n",
    "ParkLitters.createOrReplaceTempView(\"View_ParkLitters\")\n",
    "\n",
    "# Define the name of the table containing park conditions\n",
    "table_name = \"parklitters\"\n",
    "\n",
    "# SQL query to retrieve the maximum ParkConditionID from the database\n",
    "max_cond_sql = \"\"\" SELECT COALESCE(MAX(ParkLitterID), 0) AS max_table_cond_id \n",
    "                   FROM View_table_db\"\"\"\n",
    "\n",
    "# SQL query to identify common rows and add new ones if needed\n",
    "common_rows_sql = \"\"\"\n",
    "                        SELECT\n",
    "                            b.ParkLitterID,\n",
    "                            b.ParkLitterName\n",
    "                        FROM View_table_db b\n",
    "                        UNION ALL\n",
    "                        SELECT\n",
    "                            {max_table_cond_id} + ROW_NUMBER() OVER (ORDER BY a.ParkLitterName) AS ParkLitterID,\n",
    "                            a.ParkLitterName\n",
    "                        FROM View_ParkLitters a\n",
    "                        LEFT JOIN View_table_db b ON trim(a.ParkLitterName) = trim(b.ParkLitterName)\n",
    "                        WHERE b.ParkLitterID IS NULL\n",
    "            \"\"\"\n",
    "\n",
    "# Call the function to update park conditions\n",
    "ParkLitters = update_table_db(spark, jdbc_url, connection_properties, table_name, max_cond_sql, common_rows_sql,  ParkLitters)\n",
    "\n",
    "# Create or replace a temporary view from the DataFrame \n",
    "ParkLitters.createOrReplaceTempView(\"View_ParkLitters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa90dab-8948-436c-b910-2044fb46ce8f",
   "metadata": {},
   "source": [
    "## Animals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "446798db-c395-4ffa-bf8f-cabb14f7e66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the \"OtherAnimalSightings\" column from the DataFrame\n",
    "ParksAnimals = df_park.select(\"OtherAnimalSightings\")\n",
    "\n",
    "# Fill null values in the \"OtherAnimalSightings\" column with \"ND\"\n",
    "Animals = ParksAnimals.withColumn(\"OtherAnimalSightings\", when(col(\"OtherAnimalSightings\").isNull(), \"ND\").otherwise(col(\"OtherAnimalSightings\")))\n",
    "\n",
    "# Use regexp_replace to remove everything within parentheses, including the parentheses\n",
    "Animals = Animals.withColumn(\"OtherAnimalSightings\", regexp_replace(\"OtherAnimalSightings\", \"\\([^)]+\\)\", \"\"))\n",
    "\n",
    "# Split each row into a list of words using comma as delimiter\n",
    "Animals = Animals.withColumn(\"Animal_List\", split(\"OtherAnimalSightings\", \",\"))\n",
    "\n",
    "# Expand the list into separate rows\n",
    "Animals = Animals.withColumn(\"AnimalName\", explode(\"Animal_List\"))\n",
    "\n",
    "# Apply trim to each word in the list\n",
    "Animals = Animals.withColumn(\"AnimalName\", trim(\"AnimalName\"))\n",
    "\n",
    "# Remove duplicates\n",
    "Animals = Animals.dropDuplicates([\"AnimalName\"])\n",
    "\n",
    "# Sort the results in alphabetical order\n",
    "Animals  = Animals.orderBy(\"AnimalName\")\n",
    "\n",
    "# Create a new column \"AnimalID\" with unique identifiers starting from 1\n",
    "Animals = Animals.withColumn(\"AnimalID\", monotonically_increasing_id() + 1)\n",
    "\n",
    "# Select only the \"AnimalID\" and \"AnimalName\" columns\n",
    "Animals = Animals.select(\"AnimalID\", \"AnimalName\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49008bd7-535e-4dc1-af7c-781748bf8bd0",
   "metadata": {},
   "source": [
    "### Animals | Table Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "637e6938-0bdc-4574-b619-7671031fc81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+\n",
      "|AnimalID|        AnimalName|\n",
      "+--------+------------------+\n",
      "|       1|         Blackbird|\n",
      "|       2|         Cardinals|\n",
      "|       3|               Cat|\n",
      "|       4|              Dogs|\n",
      "|       5|             Doves|\n",
      "|       6|  Downy Woodpecker|\n",
      "|       7|      Fish in Pond|\n",
      "|       8|             Geese|\n",
      "|       9|Halfeaten Dead Rat|\n",
      "|      10|             Hawks|\n",
      "|      11|            Humans|\n",
      "|      12|                ND|\n",
      "|      13|           Pigeons|\n",
      "|      14|               Rat|\n",
      "|      15|            Robins|\n",
      "|      16|        Song Birds|\n",
      "|      17|          Sparrows|\n",
      "|      18|          Starling|\n",
      "+--------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create or replace a temporary view from the DataFrame \n",
    "Animals.createOrReplaceTempView(\"View_Animals\")\n",
    "\n",
    "# Define the name of the table containing park conditions\n",
    "table_name = \"animals\"\n",
    "\n",
    "# SQL query to retrieve the maximum ParkConditionID from the database\n",
    "max_cond_sql = \"\"\" SELECT COALESCE(MAX(AnimalID), 0) AS max_table_cond_id \n",
    "                   FROM View_table_db\"\"\"\n",
    "\n",
    "# SQL query to identify common rows and add new ones if needed\n",
    "common_rows_sql = \"\"\"\n",
    "                        SELECT\n",
    "                            b.AnimalID,\n",
    "                            b.AnimalName\n",
    "                        FROM View_table_db b\n",
    "                        UNION ALL\n",
    "                        SELECT\n",
    "                            {max_table_cond_id} + ROW_NUMBER() OVER (ORDER BY a.AnimalName) AS AnimalID,\n",
    "                            a.AnimalName\n",
    "                        FROM View_Animals a\n",
    "                        LEFT JOIN View_table_db b ON trim(a.AnimalName) = trim(b.AnimalName)\n",
    "                        WHERE b.AnimalID IS NULL\n",
    "            \"\"\"\n",
    "\n",
    "# Call the function to update park conditions\n",
    "Animals = update_table_db(spark, jdbc_url, connection_properties, table_name, max_cond_sql, common_rows_sql, Animals)\n",
    "\n",
    "# Create or replace a temporary view from the DataFrame \n",
    "Animals.createOrReplaceTempView(\"View_Animals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d6c3ed-d7de-4022-9df6-63cc14633c98",
   "metadata": {},
   "source": [
    "## ParkStatus - Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0174f5-e611-4859-98b6-108773da96ad",
   "metadata": {},
   "source": [
    "## Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3577129f-6ef1-425e-a460-522fb9badc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the \"Temperature&Weather\" column from the DataFrame\n",
    "ParksTemperature = df_park.select(\"Temperature&Weather\")\n",
    "\n",
    "# Fill null values in the \"Temperature & Weather\" column with \"ND\"\n",
    "Weather = ParksTemperature.withColumn(\"Temperature&Weather\", when(col(\"Temperature&Weather\").isNull(), \"ND\").otherwise(col(\"Temperature&Weather\")))\n",
    "\n",
    "# Define a regular expression pattern to extract what follows \"degrees, \"\n",
    "degree_pattern = r'.*\\b(\\d+(?:-\\w+)?)\\s+degrees,\\s*(.*)'\n",
    "\n",
    "# Apply regexp_extract to get what comes after \"degrees, \" if it exists, or leave the column as it is\n",
    "Weather_1 = Weather.withColumn(\"WeatherName\", regexp_extract(Weather[\"Temperature&Weather\"], degree_pattern, 2))\n",
    "\n",
    "# Add a new column \"WeatherName\" with null values\n",
    "Weather_2 = Weather_1.withColumn(\"WeatherName\", when(col(\"Temperature&Weather\").contains(\"degree\") | col(\"Temperature&Weather\").contains(\"ND\"), None).otherwise(col(\"Temperature&Weather\")))\n",
    "Weather_2 = Weather_2.withColumn(\"WeatherName\", when(col(\"WeatherName\").isNull(), \"\").otherwise(col(\"WeatherName\")))\n",
    "\n",
    "# Create temporary views for the DataFrames\n",
    "Weather_1.createOrReplaceTempView(\"Weather_1\")\n",
    "Weather_2.createOrReplaceTempView(\"Weather_2\")\n",
    "\n",
    "# Perform a full join using SQL\n",
    "# Add the positions of \"with\" and \"but\" in the columns of interest to the DataFrame\n",
    "Weathers = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        COALESCE(w1.`Temperature&Weather`, w2.`Temperature&Weather`) AS `Temperature&Weather`,\n",
    "        COALESCE(w1.WeatherName, w2.WeatherName) AS WeatherName,\n",
    "        INSTR(COALESCE(w1.WeatherName, w2.WeatherName), 'with') AS PositionWith,\n",
    "        INSTR(COALESCE(w1.WeatherName, w2.WeatherName), 'but') AS PositionBut\n",
    "    FROM Weather_1 w1\n",
    "    FULL OUTER JOIN Weather_2 w2\n",
    "    ON w1.`Temperature&Weather` = w2.`Temperature&Weather`\n",
    "\"\"\")\n",
    "\n",
    "# Create a temporary view for the resulting DataFrame\n",
    "Weathers.createOrReplaceTempView(\"Weather_3\")\n",
    "\n",
    "# Extract weather conditions from the combined \"WeatherName\" column\n",
    "Weathers = spark.sql(\"\"\"\n",
    "    SELECT `Temperature&Weather`,\n",
    "           CASE\n",
    "                WHEN PositionWith > 0 THEN \n",
    "                    SUBSTRING(COALESCE(WeatherName), 1, PositionWith - 1)\n",
    "                WHEN PositionBut > 0 THEN \n",
    "                    SUBSTRING(COALESCE(WeatherName), 1, PositionBut - 1)\n",
    "                ELSE \n",
    "                    WeatherName\n",
    "        END AS WeatherName\n",
    "    FROM Weather_3 \n",
    "\"\"\")\n",
    "\n",
    "# Define a regular expression pattern to detect absence of the word \"degrees\"\n",
    "regex_pattern = r\"^(?!.*\\bdegrees\\b).*$\"\n",
    "\n",
    "# Use regexp_extract to identify entries that do not contain the word \"degrees\" and are not \"ND\"\n",
    "Weathers = Weathers.withColumn(\n",
    "    \"WeatherName\",\n",
    "    when(col(\"Temperature&Weather\") == \"ND\", col(\"WeatherName\")).otherwise(\n",
    "        when(regexp_extract(col(\"Temperature&Weather\"), regex_pattern, 0) != \"\", col(\"Temperature&Weather\")).otherwise(col(\"WeatherName\"))\n",
    "    )\n",
    ")\n",
    "\n",
    "# Fill null values in the \"Temperature & Weather\" column with \"ND\" if it is empty\n",
    "Weathers = Weathers.withColumn(\"WeatherName\", when(col(\"WeatherName\").isNull() | (col(\"WeatherName\") == \"\"), \"ND\").otherwise(col(\"WeatherName\")))\n",
    "\n",
    "# Sort the results alphabetically\n",
    "Weathers = Weathers.orderBy(\"WeatherName\")\n",
    "\n",
    "# Split each row into a list of words using comma as delimiter\n",
    "Weathers = Weathers.withColumn(\"WeatherName_List\", split(\"WeatherName\", \",\"))\n",
    "\n",
    "# Expand the list into separate rows\n",
    "Weathers = Weathers.withColumn(\"WeatherName\", explode(\"WeatherName_List\"))\n",
    "\n",
    "# Apply trim to each word in the list\n",
    "Weathers = Weathers.withColumn(\"WeatherName\", trim(Weathers[\"WeatherName\"]))\n",
    "\n",
    "# Select only the \"WeatherName\" column\n",
    "Weathers = Weathers.select(\"WeatherName\")\n",
    "\n",
    "# Fill null values in the \"Temperature & Weather\" column with \"ND\" if it is empty\n",
    "Weathers = Weathers.withColumn(\"WeatherName\", when(col(\"WeatherName\").isNull() | (col(\"WeatherName\") == \"\"), \"ND\").otherwise(col(\"WeatherName\")))\n",
    "\n",
    "# Remove duplicates\n",
    "Weathers = Weathers.dropDuplicates([\"WeatherName\"])\n",
    "\n",
    "# Sort the results alphabetically\n",
    "Weathers = Weathers.orderBy(F.lower(F.col(\"WeatherName\")))\n",
    "\n",
    "# Create a new column \"WeatherID\" with unique identifiers starting from 1\n",
    "Weathers = Weathers.withColumn(\"WeatherID\", monotonically_increasing_id() + 1)\n",
    "\n",
    "# Select only the \"WeatherID\" and \"WeatherName\" columns\n",
    "Weathers = Weathers.select(\"WeatherID\", \"WeatherName\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e0062e-98ca-489c-ae1e-977da4a8184e",
   "metadata": {},
   "source": [
    "### Weathers | Table Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05644476-dd1b-4ce6-ac87-98bfd431ce21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|WeatherID|WeatherName|\n",
      "+---------+-----------+\n",
      "|        1|     chilly|\n",
      "|        2|      clear|\n",
      "|        3|       cold|\n",
      "|        4|        dry|\n",
      "|        5|         ND|\n",
      "|        6|    NW wind|\n",
      "|        7|      sunny|\n",
      "|        8|      windy|\n",
      "+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create or replace a temporary view from the DataFrame \n",
    "Weathers.createOrReplaceTempView(\"View_Weathers\")\n",
    "\n",
    "# Define the name of the table containing park conditions\n",
    "table_name = \"weathers\"\n",
    "\n",
    "# SQL query to retrieve the maximum ParkConditionID from the database\n",
    "max_cond_sql = \"\"\" SELECT COALESCE(MAX(WeatherID), 0) AS max_table_cond_id \n",
    "                   FROM View_table_db\"\"\"\n",
    "\n",
    "# SQL query to identify common rows and add new ones if needed\n",
    "common_rows_sql = \"\"\"\n",
    "                        SELECT\n",
    "                            b.WeatherID,\n",
    "                            b.WeatherName\n",
    "                        FROM View_table_db b\n",
    "                        UNION ALL\n",
    "                        SELECT\n",
    "                            {max_table_cond_id} + ROW_NUMBER() OVER (ORDER BY a.WeatherName) AS WeatherID,\n",
    "                            a.WeatherName\n",
    "                        FROM View_Weathers a\n",
    "                        LEFT JOIN View_table_db b ON trim(a.WeatherName) = trim(b.WeatherName)\n",
    "                        WHERE b.WeatherID IS NULL\n",
    "            \"\"\"\n",
    "\n",
    "# Call the function to update park conditions\n",
    "Weathers = update_table_db(spark, jdbc_url, connection_properties, table_name, max_cond_sql, common_rows_sql, Weathers)\n",
    "\n",
    "Weathers.createOrReplaceTempView(\"View_Weathers\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230708be-867f-4b15-bd0a-71e96627efe6",
   "metadata": {},
   "source": [
    "## ParkStatus processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6367f3fa-d48c-43d2-b06a-8d5d6e3cc7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+---------+--------+-----------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------------+--------------+--------------------+----------+--------------------+------------+---------------+------------+\n",
      "|ParkID|      Date|StartTime| EndTime|TotalTimeinminutesifavailable|    ParkConditions_1|            Litter_1| Temperature&Weather|OtherAnimalSightings|             Weather|Temperature_degrees|ParkConditions|   ParkConditionsObs|ParkLitter|       ParkLitterObs|ParkLitterID|ParkConditionID|ParkStatusID|\n",
      "+------+----------+---------+--------+-----------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------------+--------------+--------------------+----------+--------------------+------------+---------------+------------+\n",
      "|  17.0|03/01/2020| 15:35:00|15:45:00|                           10|                Calm|                None|42 degrees, windy...|Humans, Dogs, Pig...|   windy, dry, clear|                 42|          Calm|                    |      None|                    |           3|              2|           1|\n",
      "|  19.0|03/01/2020| 15:34:00|16:04:00|                           30|                Calm|                None|   44 degrees, sunny|Humans, Pigeons, Cat|               sunny|                 44|          Calm|                    |      None|                    |           3|              2|           2|\n",
      "|   5.0|03/01/2020| 15:15:00|15:45:00|                           30|                Calm|                  ND|                  ND|        Humans, Dogs|                  ND|                 ND|          Calm|                    |        ND|                    |           2|              2|           3|\n",
      "|  12.0|03/01/2020| 15:01:00|15:45:00|                           44|                Calm|                  ND|        windy, clear|Humans (Joggers, ...|        windy, clear|                 ND|          Calm|                    |        ND|                    |           2|              2|           4|\n",
      "|  24.0|03/01/2020| 15:00:00|15:35:00|                           35|                Calm|                  ND|36 degrees, cold,...|     Humans, Pigeons|         cold, windy|                 36|          Calm|                    |        ND|                    |           2|              2|           5|\n",
      "|   2.0|03/01/2020| 15:30:00|16:00:00|                           30|                Calm|      Some, in trees|         cold, clear|Humans, Hawks, Do...|         cold, clear|                 ND|          Calm|                    |      Some|            in trees|           4|              2|           6|\n",
      "|   3.0|03/01/2020| 15:21:00|16:15:00|                           54|Calm, pickup base...|Some, especially ...|          43 degrees|Humans, Dogs (3, ...|                  ND|                 43|          Calm|pickup baseball game|      Some|especially caught...|           4|              2|           7|\n",
      "|   4.0|03/01/2020| 15:15:00|15:45:00|                           30|                Calm|Some, backside of...|   43 degrees, clear|        Humans, Dogs|               clear|                 43|          Calm|                    |      Some|    backside of park|           4|              2|           8|\n",
      "|   9.0|03/01/2020| 15:00:00|16:00:00|                           60|Calm, 2030 ppl on...|                Some|   45 degrees, sunny|Humans, Dogs, Spa...|               sunny|                 45|          Calm|2030 ppl on each ...|      Some|                    |           4|              2|           9|\n",
      "|  15.0|03/01/2020| 15:35:00|16:15:00|                           40|                Calm|Some, mostly in t...|   48 degrees, sunny|Humans, Dogs, Pig...|               sunny|                 48|          Calm|                    |      Some|     mostly in trees|           4|              2|          10|\n",
      "|  23.0|03/01/2020| 15:06:00|15:50:00|                           44|                Calm|                Some|45 degrees, sunny...|Humans, Dogs, Pig...|      sunny, NW wind|                 45|          Calm|                    |      Some|                    |           4|              2|          11|\n",
      "|   6.0|03/01/2020| 15:45:00|16:15:00|                           30|Calm, re: humans,...|            Abundant|   42 degrees, clear|Hawks, Dogs, Pigeons|               clear|                 42|          Calm|re: humans, but a...|  Abundant|                    |           1|              2|          12|\n",
      "|  21.0|03/01/2020| 15:25:00|15:50:00|                           25|              Medium|                Some|       chilly, sunny|Humans, Dogs, Pig...|       chilly, sunny|                 ND|        Medium|                    |      Some|                    |           4|              4|          13|\n",
      "|  10.0|03/01/2020| 15:20:00|16:00:00|                           40|                Busy|                None|45 degrees, sunny...|        Humans, Dogs|sunny with shade ...|                 45|          Busy|                    |      None|                    |           3|              1|          14|\n",
      "|  16.0|03/01/2020| 15:47:00|16:38:00|                           51|                Busy|                None|42 degrees, windy...|Humans, Dogs, Pig...|   windy, dry, clear|                 42|          Busy|                    |      None|                    |           3|              1|          15|\n",
      "|   7.0|03/01/2020| 14:30:00|15:50:00|                           80|                Busy|                  ND|   43 degrees, sunny|Humans, Dogs, Pig...|               sunny|                 43|          Busy|                    |        ND|                    |           2|              1|          16|\n",
      "|   8.0|03/01/2020| 15:15:00|15:45:00|                           30|                Busy|                  ND|   40 degrees, sunny|Humans, Dogs, Pig...|               sunny|                 40|          Busy|                    |        ND|                    |           2|              1|          17|\n",
      "|   1.0|03/01/2020| 15:14:00|16:05:00|                           51|                Busy|                Some|   43 degrees, sunny|Humans, Dogs, Pig...|               sunny|                 43|          Busy|                    |      Some|                    |           4|              1|          18|\n",
      "|  13.1|03/01/2020| 15:30:00|16:00:00|                           30|                Busy|                Some|   44 degrees, sunny| Humans, Dogs (Gray)|               sunny|                 44|          Busy|                    |      Some|                    |           4|              1|          19|\n",
      "|  13.2|03/01/2020| 15:30:00|16:00:00|                           30|                Busy|                Some|   43 degrees, sunny|     Humans, Pigeons|               sunny|                 43|          Busy|                    |      Some|                    |           4|              1|          20|\n",
      "+------+----------+---------+--------+-----------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------------+--------------+--------------------+----------+--------------------+------------+---------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select relevant columns from the DataFrame\n",
    "ParkStatus = df_park.select(\"ParkID\", \"Date\", \"StartTime\", \"EndTime\", \"TotalTimeinminutesifavailable\", \"ParkConditions\", \"Litter\", \"Temperature&Weather\", \"OtherAnimalSightings\")\n",
    "\n",
    "# Extract temperature information from the \"Temperature&Weather\" column\n",
    "ParkStatus = ParkStatus.withColumn(\n",
    "    \"Weather\",\n",
    "    when(\n",
    "        col(\"Temperature&Weather\").isNull() | (col(\"Temperature&Weather\") == \"\"),\n",
    "        \"ND\"\n",
    "    ).otherwise(\n",
    "        trim(substring_index(col(\"Temperature&Weather\"), \"degrees,\", -1))\n",
    "    )\n",
    ")\n",
    "\n",
    "# Replace content with \"ND\" if it contains \"degrees\"\n",
    "ParkStatus = ParkStatus.withColumn(\n",
    "    \"Weather\",\n",
    "    when(col(\"Weather\").contains(\"degrees\"), \"ND\").otherwise(col(\"Weather\"))\n",
    ")\n",
    "\n",
    "# Extract temperature in degrees from the \"Temperature&Weather\" column\n",
    "ParkStatus = ParkStatus.withColumn(\n",
    "    \"Temperature_degrees\",\n",
    "    regexp_extract(col(\"Temperature&Weather\"), r\"(\\d+)\", 1)\n",
    ")\n",
    "\n",
    "# Replace non-numeric values with \"ND\"\n",
    "ParkStatus = ParkStatus.withColumn(\n",
    "    \"Temperature_degrees\",\n",
    "    when(col(\"Temperature_degrees\").cast(\"int\").isNull(), \"ND\").otherwise(col(\"Temperature_degrees\"))\n",
    ")\n",
    "\n",
    "# Rename the column\n",
    "ParkStatus = ParkStatus.withColumnRenamed(\"ParkConditions\", \"ParkConditions_1\")\n",
    "\n",
    "# Extract the primary park condition\n",
    "ParkStatus = ParkStatus.withColumn(\n",
    "    \"ParkConditions\",\n",
    "    regexp_replace(col(\"ParkConditions_1\"), \",.*\", \"\")\n",
    ")\n",
    "\n",
    "# Extract observations related to park conditions\n",
    "ParkStatus = ParkStatus.withColumn(\n",
    "    \"ParkConditionsObs\",\n",
    "    when(col(\"ParkConditions_1\").contains(','),  # If comma is present\n",
    "         trim(expr(\"substring(ParkConditions_1, instr(ParkConditions_1, ',') + 1)\")))\n",
    "    .otherwise(\"\")  # If no comma is present\n",
    ")\n",
    "\n",
    "# Rename the column\n",
    "ParkStatus = ParkStatus.withColumnRenamed(\"Litter\", \"Litter_1\")\n",
    "\n",
    "# Extract the primary litter condition\n",
    "ParkStatus = ParkStatus.withColumn(\n",
    "    \"ParkLitter\",\n",
    "    regexp_replace(col(\"Litter_1\"), \",.*\", \"\")\n",
    ")\n",
    "\n",
    "# Extract observations related to litter conditions\n",
    "ParkStatus = ParkStatus.withColumn(\n",
    "    \"ParkLitterObs\",\n",
    "    when(col(\"Litter_1\").contains(','),  # If comma is present\n",
    "         trim(expr(\"substring(Litter_1, instr(Litter_1, ',') + 1)\")))\n",
    "    .otherwise(\"\")  # If no comma is present\n",
    ")\n",
    "\n",
    "# Create a temporary view for the DataFrame\n",
    "ParkStatus.createOrReplaceTempView(\"View_ParkStatus\")\n",
    "\n",
    "# Perform a left join using SQL\n",
    "ParkStatus = spark.sql(\"\"\"\n",
    "    SELECT PkSt.*, Ltt.ParkLitterID, Cnd.ParkConditionID\n",
    "    FROM View_ParkStatus PkSt LEFT JOIN View_ParkLitters    Ltt ON trim(PkSt.ParkLitter)     = trim(Ltt.ParkLitterName)\n",
    "                              LEFT JOIN View_ParkConditions Cnd ON trim(PkSt.ParkConditions) = trim(Cnd.ParkConditionName)\n",
    "\"\"\")\n",
    "\n",
    "# Create a new column \"ParkStatusID\" with unique identifiers starting from 1\n",
    "ParkStatus = ParkStatus.withColumn(\"ParkStatusID\", monotonically_increasing_id() + 1)\n",
    "\n",
    "# Create a temporary view for the DataFrame\n",
    "ParkStatus.createOrReplaceTempView(\"View_ParkStatus\")\n",
    "\n",
    "# Show the DataFrame\n",
    "ParkStatus.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed56ef98-e127-4efb-a3c6-527435489614",
   "metadata": {},
   "source": [
    "## ParkStatusWeather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37c5191f-9351-40e2-9d2c-74873e97bd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########\n",
    "# Weather #\n",
    "###########\n",
    "\n",
    "# Remove trailing comma from \"Weather\", if it exists\n",
    "ParkStatus = ParkStatus.withColumn(\n",
    "    \"Weather\",\n",
    "    regexp_replace(col(\"Weather\"), \",$\", \"\")\n",
    ")\n",
    "\n",
    "# Extract text following \"but\" or \"with\" (including \"but\" or \"with\") into the \"WeatherObs\" column\n",
    "ParkStatus = ParkStatus.withColumn(\n",
    "    \"WeatherObs\",\n",
    "    regexp_extract(col(\"Weather\"), \"(but|with).*$\", 0)\n",
    ")\n",
    "\n",
    "# Remove the extracted text from \"Weather\" and leave only the text before \"but\" or \"with\"\n",
    "ParkStatus = ParkStatus.withColumn(\n",
    "    \"Weather\",\n",
    "    trim(regexp_replace(col(\"Weather\"), \"(but|with).*$\", \"\"))\n",
    ")\n",
    "\n",
    "# Create a temporary view for the DataFrame\n",
    "ParkStatus.createOrReplaceTempView(\"View_ParkStatus\")\n",
    "\n",
    "# Perform a full join using SQL\n",
    "ParkStatusWheater = spark.sql(\"\"\"\n",
    "    SELECT ParkStatusID, Weather, WeatherObs\n",
    "    FROM View_ParkStatus \n",
    "\"\"\")\n",
    "\n",
    "# Split the column into separate rows and remove additional whitespace\n",
    "ParkStatusWheater = ParkStatusWheater.withColumn(\"Weather\", explode(split(trim(ParkStatusWheater[\"Weather\"]), \", \")))\n",
    "\n",
    "# Remove commas from the column\n",
    "ParkStatusWheater = ParkStatusWheater.withColumn('Weather', regexp_replace('Weather', ',', ''))\n",
    "\n",
    "# Replace empty values in the 'Weather' column with 'ND'\n",
    "ParkStatusWheater = ParkStatusWheater.withColumn('Weather', regexp_replace(col('Weather'), '^$', 'ND'))\n",
    "\n",
    "# Create a new column \"ParkStatusWheaterID\" with unique identifiers starting from 1\n",
    "ParkStatusWheater  = ParkStatusWheater.withColumn(\"ParkStatusWheaterID\", monotonically_increasing_id() + 1)\n",
    "\n",
    "ParkStatusWheater.createOrReplaceTempView(\"View_ParkStatusWheater\")\n",
    "\n",
    "# Perform a full join using SQL\n",
    "ParkStatusWheater = spark.sql(\"\"\"\n",
    "    SELECT a.ParkStatusWheaterID, a.ParkStatusID, b.WeatherID, a.WeatherObs\n",
    "    FROM View_ParkStatusWheater a LEFT JOIN View_Weathers b on trim(a.Weather) = trim(b.WeatherName)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4de991-c0e6-4b02-a732-67c988f0d142",
   "metadata": {},
   "source": [
    "### ParkStatusWheater | Table Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43609073-c9f6-47a5-9a0a-f25fb6642fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------+---------+----------------+\n",
      "|ParkStatusWheaterID|ParkStatusID|WeatherID|      WeatherObs|\n",
      "+-------------------+------------+---------+----------------+\n",
      "|                  1|           1|        7|                |\n",
      "|                  2|           2|        3|                |\n",
      "|                  3|           2|        2|                |\n",
      "|                  4|           3|        5|                |\n",
      "|                  5|           4|        2|                |\n",
      "|                  6|           5|        5|                |\n",
      "|                  7|           6|        2|                |\n",
      "|                  8|           7|        7|                |\n",
      "|                  9|           8|        7|                |\n",
      "|                 10|           9|        7|                |\n",
      "|                 11|          10|        7|with shade spots|\n",
      "|                 12|          11|        5|                |\n",
      "|                 13|          12|        8|                |\n",
      "|                 14|          12|        2|                |\n",
      "|                 15|          13|        7|                |\n",
      "|                 16|          14|        7|                |\n",
      "|                 17|          15|        7|                |\n",
      "|                 18|          16|        7|                |\n",
      "|                 19|          17|        8|                |\n",
      "|                 20|          17|        4|                |\n",
      "+-------------------+------------+---------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create or replace a temporary view from the DataFrame \n",
    "ParkStatusWheater.createOrReplaceTempView(\"View_ParkStatusWheater\")\n",
    "\n",
    "# Define the name of the table containing park conditions\n",
    "table_name = \"parkstatuswheater\"\n",
    "\n",
    "# SQL query to retrieve the maximum ParkConditionID from the database\n",
    "max_cond_sql = \"\"\" SELECT COALESCE(MAX(ParkStatusWheaterID), 0) AS max_table_cond_id \n",
    "                   FROM View_table_db\"\"\"\n",
    "\n",
    "# SQL query to identify common rows and add new ones if needed\n",
    "common_rows_sql = \"\"\"\n",
    "                        SELECT\n",
    "                            b.ParkStatusWheaterID,\n",
    "                            b.ParkStatusID,\n",
    "                            b.WeatherID,\n",
    "                            b.WeatherObs\n",
    "                        FROM View_table_db b\n",
    "                        UNION ALL\n",
    "                        SELECT\n",
    "                            {max_table_cond_id} + ROW_NUMBER() OVER (ORDER BY a.ParkStatusID, a.WeatherID) AS ParkStatusWheaterID,\n",
    "                            a.ParkStatusID,\n",
    "                            a.WeatherID,\n",
    "                            a.WeatherObs\n",
    "                        FROM View_ParkStatusWheater a\n",
    "                        LEFT JOIN View_table_db b ON a.ParkStatusID = b.ParkStatusID AND\n",
    "                                                     a.WeatherID    = b.WeatherID    AND\n",
    "                                                     a.WeatherObs   = b.WeatherObs \n",
    "                        WHERE b.ParkStatusWheaterID IS NULL\n",
    "            \"\"\"\n",
    "\n",
    "# Call the function to update park conditions\n",
    "ParkStatusWheater = update_table_db(spark, jdbc_url, connection_properties, table_name, max_cond_sql, common_rows_sql, ParkStatusWheater)\n",
    "\n",
    "ParkStatusWheater.createOrReplaceTempView(\"View_ParkStatusWheater\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aade3573-ae75-4243-8f42-1d0baed4d777",
   "metadata": {},
   "source": [
    "## ParkStatusAnimals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70927482-3317-4317-a008-a11bb4204a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "ParkStatusAnimals = spark.sql(\"\"\"\n",
    "    SELECT ParkStatusID, OtherAnimalSightings as Animal\n",
    "    FROM View_ParkStatus \n",
    "\"\"\")\n",
    "\n",
    "# Define the regular expression to find text within parentheses containing commas\n",
    "pattern = \"\\(([^)]*),([^)]*)\\)\"\n",
    "\n",
    "# Replace commas within parentheses with \"xxzxx\"\n",
    "ParkStatusAnimals = ParkStatusAnimals.withColumn(\"Animal\", regexp_replace(ParkStatusAnimals[\"Animal\"], pattern, \"($1xxzxx$2)\"))\n",
    "\n",
    "# Split the column into separate rows and remove additional whitespace\n",
    "ParkStatusAnimals = ParkStatusAnimals.withColumn(\"Animal\", explode(split(trim(ParkStatusAnimals[\"Animal\"]), \", \")))\n",
    "\n",
    "# Extract text within parentheses into a new column\n",
    "ParkStatusAnimals = ParkStatusAnimals.withColumn(\"ParkStatusAnimalObs\", regexp_extract(col(\"Animal\"), \"\\(([^)]*)\\)\", 1))\n",
    "\n",
    "# Remove parentheses from the OtherAnimalSightings column\n",
    "ParkStatusAnimals = ParkStatusAnimals.withColumn(\"Animal\", regexp_replace(col(\"Animal\"), \"\\([^)]*\\)\", \"\"))\n",
    "\n",
    "# Replace \"xxzxx\" with commas in the ParkStatusAnimalObs column\n",
    "ParkStatusAnimals = ParkStatusAnimals.withColumn(\"ParkStatusAnimalObs\", regexp_replace(col(\"ParkStatusAnimalObs\"), \"xxzxx\", \", \"))\n",
    "\n",
    "# Create a new column \"ParkStatusAnimalID\" with unique identifiers starting from 1\n",
    "ParkStatusAnimals  = ParkStatusAnimals.withColumn(\"ParkStatusAnimalID\", monotonically_increasing_id() + 1)\n",
    "\n",
    "ParkStatusAnimals.createOrReplaceTempView(\"View_ParkStatusAnimals\")\n",
    "\n",
    "# Perform a left join using SQL\n",
    "ParkStatusAnimals = spark.sql(\"\"\"\n",
    "    SELECT ParkStatusAnimalID, ParkStatusID, AnimalID, ParkStatusAnimalObs\n",
    "    FROM View_ParkStatusAnimals a LEFT JOIN View_Animals b on trim(a.Animal) = trim(b.AnimalName)  \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b37dc7d-c4ee-4dfd-93dc-dacc250cf5b2",
   "metadata": {},
   "source": [
    "### ParkStatusAnimals | Table Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c09273a3-ef0d-4e1c-80ff-de1b6243424e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------+--------+-------------------+\n",
      "|ParkStatusAnimalID|ParkStatusID|AnimalID|ParkStatusAnimalObs|\n",
      "+------------------+------------+--------+-------------------+\n",
      "|                 1|           1|      11|                   |\n",
      "|                 2|           1|       4|                   |\n",
      "|                 3|           1|      13|                   |\n",
      "|                 4|           1|       2|                   |\n",
      "|                 5|           2|      11|                   |\n",
      "|                 6|           2|      10|                   |\n",
      "|                 7|           2|       4|                   |\n",
      "|                 8|           2|      13|                   |\n",
      "|                 9|           2|      14|                   |\n",
      "|                10|           3|      11|                   |\n",
      "|                11|           3|       4| 3,  all on leashes|\n",
      "|                12|           3|       6|                  2|\n",
      "|                13|           3|      15|                   |\n",
      "|                14|           3|      16|                   |\n",
      "|                15|           4|      11|                   |\n",
      "|                16|           4|       4|                   |\n",
      "|                17|           5|      11|                   |\n",
      "|                18|           5|       4|                   |\n",
      "|                19|           6|      10|                   |\n",
      "|                20|           6|       4|                   |\n",
      "+------------------+------------+--------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create or replace a temporary view from the DataFrame \n",
    "ParkStatusAnimals.createOrReplaceTempView(\"View_ParkStatusAnimals\")\n",
    "\n",
    "# Define the name of the table containing park conditions\n",
    "table_name = \"parkstatusanimals\"\n",
    "\n",
    "# SQL query to retrieve the maximum ParkConditionID from the database\n",
    "max_cond_sql = \"\"\" SELECT COALESCE(MAX(ParkStatusAnimalID), 0) AS max_table_cond_id \n",
    "                   FROM View_table_db\"\"\"\n",
    "\n",
    "# SQL query to identify common rows and add new ones if needed\n",
    "common_rows_sql = \"\"\"\n",
    "                        SELECT\n",
    "                            b.ParkStatusAnimalID, \n",
    "                            b.ParkStatusID, \n",
    "                            b.AnimalID, \n",
    "                            b.ParkStatusAnimalObs\n",
    "                        FROM View_table_db b\n",
    "                        UNION ALL\n",
    "                        SELECT\n",
    "                            {max_table_cond_id} + ROW_NUMBER() OVER (ORDER BY a.ParkStatusID, a.AnimalID) AS ParkStatusAnimalID,\n",
    "                            a.ParkStatusID,\n",
    "                            a.AnimalID, \n",
    "                            a.ParkStatusAnimalObs\n",
    "                        FROM View_ParkStatusAnimals a\n",
    "                        LEFT JOIN View_table_db b ON a.ParkStatusID        = b.ParkStatusID  AND\n",
    "                                                     a.AnimalID            = b.AnimalID      AND\n",
    "                                                     a.ParkStatusAnimalObs = b.ParkStatusAnimalObs \n",
    "                        WHERE b.ParkStatusAnimalID IS NULL\n",
    "            \"\"\"\n",
    "\n",
    "# Call the function to update park conditions\n",
    "ParkStatusAnimals = update_table_db(spark, jdbc_url, connection_properties, table_name, max_cond_sql, common_rows_sql, ParkStatusAnimals)\n",
    "\n",
    "ParkStatusAnimals.createOrReplaceTempView(\"View_ParkStatusAnimals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7380e8a-3c68-4796-bdf2-e3f2a17f2d88",
   "metadata": {},
   "source": [
    "## ParkStatus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b344b83b-45d7-4c79-9312-26cde1242deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+-------------+--------------+-------------------+-----------------+------------------+---------------+-----------------------+------------+--------------------+----------------------------+\n",
      "|ParkStatusID|ParkID|ParkSectionID|ParkStatusDate|ParkStatusStartTime|ParkStatusEndTime|ParkStatusTotalTme|ParkConditionID|ParkStatusConditionsObs|ParkLitterID| ParkStatusLitterObs|ParkStatusTemperatureDegrees|\n",
      "+------------+------+-------------+--------------+-------------------+-----------------+------------------+---------------+-----------------------+------------+--------------------+----------------------------+\n",
      "|          18|    15|         NULL|    03/01/2020|           15:35:00|         16:15:00|                40|              2|                       |           4|     mostly in trees|                          48|\n",
      "|          14|     9|         NULL|    03/01/2020|           15:00:00|         16:00:00|                60|              2|   2030 ppl on each ...|           4|                    |                          45|\n",
      "|           6|     7|         NULL|    03/01/2020|           14:30:00|         15:50:00|                80|              1|                       |           2|                    |                          43|\n",
      "|           1|    10|         NULL|    03/01/2020|           15:20:00|         16:00:00|                40|              1|                       |           3|                    |                          45|\n",
      "|          11|     2|         NULL|    03/01/2020|           15:30:00|         16:00:00|                30|              2|                       |           4|            in trees|                          ND|\n",
      "|          16|    13|            3|    03/01/2020|           15:30:00|         16:00:00|                30|              1|                       |           4|                    |                          43|\n",
      "|          17|    14|         NULL|    03/01/2020|           15:25:00|         15:55:00|                30|              1|                       |           4|                    |                          40|\n",
      "|           7|     8|         NULL|    03/01/2020|           15:15:00|         15:45:00|                30|              1|                       |           2|                    |                          40|\n",
      "|          19|    18|         NULL|    03/01/2020|           15:37:00|         16:00:00|                23|              5|                       |           4|                    |                          43|\n",
      "|           5|     5|            1|    03/01/2020|           15:15:00|         15:45:00|                30|              2|                       |           2|                    |                          ND|\n",
      "|          15|    13|            2|    03/01/2020|           15:30:00|         16:00:00|                30|              1|                       |           4|                    |                          44|\n",
      "|           3|    17|         NULL|    03/01/2020|           15:35:00|         15:45:00|                10|              2|                       |           3|                    |                          42|\n",
      "|           8|    11|         NULL|    03/01/2020|           15:15:00|         15:45:00|                30|              5|                       |           2|                    |                          ND|\n",
      "|          12|     3|         NULL|    03/01/2020|           15:21:00|         16:15:00|                54|              2|   pickup baseball game|           4|especially caught...|                          43|\n",
      "|           2|    16|         NULL|    03/01/2020|           15:47:00|         16:38:00|                51|              1|                       |           3|                    |                          42|\n",
      "|          21|     6|         NULL|    03/01/2020|           15:45:00|         16:15:00|                30|              2|   re: humans, but a...|           1|                    |                          42|\n",
      "|          10|     1|         NULL|    03/01/2020|           15:14:00|         16:05:00|                51|              1|                       |           4|                    |                          43|\n",
      "|           9|    12|         NULL|    03/01/2020|           15:01:00|         15:45:00|                44|              2|                       |           2|                    |                          ND|\n",
      "|           4|    19|         NULL|    03/01/2020|           15:34:00|         16:04:00|                30|              2|                       |           3|                    |                          44|\n",
      "|          20|    20|         NULL|    03/01/2020|           15:10:00|         15:40:00|                30|              3|                       |           4|                    |                          40|\n",
      "+------------+------+-------------+--------------+-------------------+-----------------+------------------+---------------+-----------------------+------------+--------------------+----------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove columns from \"ParkStatus\"\n",
    "ParkStatus = ParkStatus.drop(\"Weather\")\n",
    "ParkStatus = ParkStatus.drop(\"WeatherObs\")\n",
    "ParkStatus = ParkStatus.drop(\"ParkConditions\")\n",
    "ParkStatus = ParkStatus.drop(\"OtherAnimalSightings\")\n",
    "ParkStatus = ParkStatus.drop(\"ParkConditions_1\")\n",
    "ParkStatus = ParkStatus.drop(\"Temperature&Weather\")\n",
    "ParkStatus = ParkStatus.drop(\"Litter_1\")\n",
    "\n",
    "# Split the value of ParkID into two columns: IntegerPart and DecimalPart\n",
    "split_col = split(ParkStatus['ParkID'], '\\.')\n",
    "ParkStatus = ParkStatus.withColumn('ParkID_real', split_col.getItem(0))\n",
    "ParkStatus = ParkStatus.withColumn('SectionID', split_col.getItem(1))\n",
    "\n",
    "# Create a new column \"ParkStatusID\" with unique identifiers starting from 1\n",
    "ParkStatus = ParkStatus.withColumn(\"ParkStatusID\", monotonically_increasing_id() + 1)\n",
    "\n",
    "ParkStatus.createOrReplaceTempView(\"View_ParkStatus\")\n",
    "\n",
    "# Perform a left join using SQL\n",
    "ParkStatus = spark.sql(\"\"\"\n",
    "    SELECT a.ParkStatusID, CAST(a.ParkID_real AS INT) as ParkID, b.ParkSectionID, a.Date  as ParkStatusDate, a.StartTime as ParkStatusStartTime, a.EndTime as ParkStatusEndTime, a.TotalTimeinminutesifavailable as ParkStatusTotalTme,\n",
    "           a.ParkConditionID, a.ParkConditionsObs as ParkStatusConditionsObs, a.ParkLitterID, a.ParkLitterObs as ParkStatusLitterObs, a.Temperature_degrees as ParkStatusTemperatureDegrees\n",
    "    FROM View_ParkStatus a LEFT JOIN View_ParkSections b ON a.ParkID_real = b.ParkID and a.SectionID = b.SectionID\n",
    "\"\"\")\n",
    "\n",
    "ParkStatus.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5378da7-2e6d-4a2e-bec3-fdcaebe264e2",
   "metadata": {},
   "source": [
    "### ParkStatus | Table Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b62d3009-4fc9-4e61-a545-919597c843af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+-------------+--------------+-------------------+-----------------+------------------+---------------+-----------------------+------------+--------------------+----------------------------+\n",
      "|ParkStatusID|ParkID|ParkSectionID|ParkStatusDate|ParkStatusStartTime|ParkStatusEndTime|ParkStatusTotalTme|ParkConditionID|ParkStatusConditionsObs|ParkLitterID| ParkStatusLitterObs|ParkStatusTemperatureDegrees|\n",
      "+------------+------+-------------+--------------+-------------------+-----------------+------------------+---------------+-----------------------+------------+--------------------+----------------------------+\n",
      "|           1|     1|         NULL|    03/01/2020|           15:14:00|         16:05:00|                51|              1|                       |           4|                    |                          43|\n",
      "|           2|     2|         NULL|    03/01/2020|           15:30:00|         16:00:00|                30|              2|                       |           4|            in trees|                          ND|\n",
      "|           3|     3|         NULL|    03/01/2020|           15:21:00|         16:15:00|                54|              2|   pickup baseball game|           4|especially caught...|                          43|\n",
      "|           4|     4|         NULL|    03/01/2020|           15:15:00|         15:45:00|                30|              2|                       |           4|    backside of park|                          43|\n",
      "|           5|     5|            1|    03/01/2020|           15:15:00|         15:45:00|                30|              2|                       |           2|                    |                          ND|\n",
      "|           6|     6|         NULL|    03/01/2020|           15:45:00|         16:15:00|                30|              2|   re: humans, but a...|           1|                    |                          42|\n",
      "|           7|     7|         NULL|    03/01/2020|           14:30:00|         15:50:00|                80|              1|                       |           2|                    |                          43|\n",
      "|           8|     8|         NULL|    03/01/2020|           15:15:00|         15:45:00|                30|              1|                       |           2|                    |                          40|\n",
      "|           9|     9|         NULL|    03/01/2020|           15:00:00|         16:00:00|                60|              2|   2030 ppl on each ...|           4|                    |                          45|\n",
      "|          10|    10|         NULL|    03/01/2020|           15:20:00|         16:00:00|                40|              1|                       |           3|                    |                          45|\n",
      "|          11|    11|         NULL|    03/01/2020|           15:15:00|         15:45:00|                30|              5|                       |           2|                    |                          ND|\n",
      "|          12|    12|         NULL|    03/01/2020|           15:01:00|         15:45:00|                44|              2|                       |           2|                    |                          ND|\n",
      "|          13|    13|            2|    03/01/2020|           15:30:00|         16:00:00|                30|              1|                       |           4|                    |                          44|\n",
      "|          14|    13|            3|    03/01/2020|           15:30:00|         16:00:00|                30|              1|                       |           4|                    |                          43|\n",
      "|          15|    14|         NULL|    03/01/2020|           15:25:00|         15:55:00|                30|              1|                       |           4|                    |                          40|\n",
      "|          16|    15|         NULL|    03/01/2020|           15:35:00|         16:15:00|                40|              2|                       |           4|     mostly in trees|                          48|\n",
      "|          17|    16|         NULL|    03/01/2020|           15:47:00|         16:38:00|                51|              1|                       |           3|                    |                          42|\n",
      "|          18|    17|         NULL|    03/01/2020|           15:35:00|         15:45:00|                10|              2|                       |           3|                    |                          42|\n",
      "|          19|    18|         NULL|    03/01/2020|           15:37:00|         16:00:00|                23|              5|                       |           4|                    |                          43|\n",
      "|          20|    19|         NULL|    03/01/2020|           15:34:00|         16:04:00|                30|              2|                       |           3|                    |                          44|\n",
      "+------------+------+-------------+--------------+-------------------+-----------------+------------------+---------------+-----------------------+------------+--------------------+----------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create or replace a temporary view from the DataFrame \n",
    "ParkStatus.createOrReplaceTempView(\"View_ParkStatus\")\n",
    "\n",
    "# Define the name of the table containing park conditions\n",
    "table_name = \"parkstatus\"\n",
    "\n",
    "\n",
    "# SQL query to retrieve the maximum ParkConditionID from the database\n",
    "max_cond_sql = \"\"\" SELECT COALESCE(MAX(ParkStatusID), 0) AS max_table_cond_id \n",
    "                   FROM View_table_db\"\"\"\n",
    "\n",
    "# SQL query to identify common rows and add new ones if needed\n",
    "common_rows_sql = \"\"\"\n",
    "                        SELECT\n",
    "                            b.ParkStatusID,\n",
    "                            b.ParkID,\n",
    "                            b.ParkSectionID,\n",
    "                            b.ParkStatusDate,\n",
    "                            b.ParkStatusStartTime,\n",
    "                            b.ParkStatusEndTime,\n",
    "                            b.ParkStatusTotalTme,\n",
    "                            b.ParkConditionID,\n",
    "                            b.ParkStatusConditionsObs,\n",
    "                            b.ParkLitterID,\n",
    "                            b.ParkStatusLitterObs,\n",
    "                            b.ParkStatusTemperatureDegrees\n",
    "                        FROM View_table_db b\n",
    "                        UNION ALL\n",
    "                        SELECT\n",
    "                            {max_table_cond_id} + ROW_NUMBER() OVER (ORDER BY   a.ParkID,\n",
    "                                                                                a.ParkSectionID,\n",
    "                                                                                a.ParkStatusDate,\n",
    "                                                                                a.ParkStatusStartTime,\n",
    "                                                                                a.ParkStatusEndTime,\n",
    "                                                                                a.ParkStatusTotalTme,\n",
    "                                                                                a.ParkConditionID,\n",
    "                                                                                a.ParkStatusConditionsObs,\n",
    "                                                                                a.ParkLitterID,\n",
    "                                                                                a.ParkStatusLitterObs,\n",
    "                                                                                a.ParkStatusTemperatureDegrees) AS ParkStatusAnimalID,\n",
    "                            a.ParkID,\n",
    "                            a.ParkSectionID,\n",
    "                            a.ParkStatusDate,\n",
    "                            a.ParkStatusStartTime,\n",
    "                            a.ParkStatusEndTime,\n",
    "                            a.ParkStatusTotalTme,\n",
    "                            a.ParkConditionID,\n",
    "                            a.ParkStatusConditionsObs,\n",
    "                            a.ParkLitterID,\n",
    "                            a.ParkStatusLitterObs,\n",
    "                            a.ParkStatusTemperatureDegrees\n",
    "                        FROM View_ParkStatus a\n",
    "                        LEFT JOIN View_table_db b ON    a.ParkID                  = b.ParkID AND\n",
    "                                                        a.ParkSectionID           = b.ParkSectionID AND\n",
    "                                                        a.ParkStatusDate          = b.ParkStatusDate  AND\n",
    "                                                        a.ParkStatusStartTime     = b.ParkStatusStartTime AND  \n",
    "                                                        a.ParkStatusEndTime       = b.ParkStatusEndTime AND \n",
    "                                                        a.ParkStatusTotalTme      = b.ParkStatusTotalTme AND\n",
    "                                                        a.ParkConditionID         = b.ParkConditionID  AND\n",
    "                                                        a.ParkStatusConditionsObs = b.ParkStatusConditionsObs  AND\n",
    "                                                        a.ParkLitterID            = b.ParkLitterID   AND\n",
    "                                                        a.ParkStatusLitterObs     = b.ParkStatusLitterObs AND\n",
    "                                                        a.ParkStatusTemperatureDegrees = b.ParkStatusTemperatureDegrees\n",
    "                        WHERE b.ParkStatusID IS NULL\n",
    "            \"\"\"\n",
    "\n",
    "# Call the function to update park conditions\n",
    "ParkStatus = update_table_db(spark, jdbc_url, connection_properties, table_name, max_cond_sql, common_rows_sql, ParkStatus)\n",
    "\n",
    "ParkStatus.createOrReplaceTempView(\"View_ParkStatus\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3af05fe-06e6-4169-8052-8ee14832f25a",
   "metadata": {},
   "source": [
    "# RELATIONAL - SQUIRREL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df58a465-fcb4-45e7-865f-b983ebc3358a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+---------------+--------------------+----------+------------+----------------+--------------------+----------------------+------------------------+----------------+-----------------+---------------+---------------+--------------+\n",
      "|ParkID|SquirrelID|PrimaryFurColor|HighlightsinFurColor|ColorNotes|    Location|SpecificLocation|          Activities|InteractionswithHumans|OtherNotesorObservations|SquirrelLatitude|SquirrelLongitude|Min_Height_Feet|Max_Height_Feet|SquirrelDataID|\n",
      "+------+----------+---------------+--------------------+----------+------------+----------------+--------------------+----------------------+------------------------+----------------+-----------------+---------------+---------------+--------------+\n",
      "|     1|   A-01-01|           Gray|               White|        ND|Ground Plane|              ND|            Foraging|           Indifferent|                      ND|        40.85941|       -73.933936|              0|              0|             1|\n",
      "|     1|   A-01-02|           Gray|               White|        ND|Ground Plane|              ND|            Foraging|           Indifferent|            Looks skinny|       40.859436|       -73.933937|              0|              0|             2|\n",
      "|     1|   A-01-03|           Gray|               White|        ND|Ground Plane|              ND|Eating, Digging s...|           Indifferent|                      ND|       40.859416|       -73.933894|              0|              0|             3|\n",
      "|     1|   A-01-04|           Gray|               White|        ND|Ground Plane|              ND|             Running|           Indifferent|                      ND|       40.859418|       -73.933895|              0|              0|             4|\n",
      "|     1|   A-01-05|           Gray|            Cinnamon|        ND|Ground Plane|              ND|     Running, Eating|           Indifferent|           She left food|       40.859493|        -73.93359|              0|              0|             5|\n",
      "|     1|   A-01-06|           Gray|            Cinnamon|        ND|Ground Plane|              ND|            Climbing|           Indifferent|                      ND|       40.860825|       -73.932871|              0|              0|             6|\n",
      "|     1|   A-01-07|           Gray|               White|        ND|Ground Plane|              ND|            Foraging|           Indifferent|                      ND|       40.860225|       -73.933143|              0|              0|             7|\n",
      "|     1|   A-01-08|          Black|                Gray|        ND|Above Ground|              ND|            Climbing|             Runs From|                      ND|       40.859965|       -73.933412|             10|             10|             8|\n",
      "|     1|   A-01-09|           Gray|               White|        ND|Ground Plane|              ND|            Foraging|           Indifferent|                      ND|       40.859892|       -73.933326|              0|              0|             9|\n",
      "|     1|   A-01-10|           Gray|               White|        ND|Ground Plane|              ND|     Eating, Digging|           Indifferent|                      ND|       40.859636|       -73.933717|              0|              0|            10|\n",
      "|     1|   A-01-11|           Gray|               Black|        ND|Ground Plane|              ND|     Eating, Digging|           Indifferent|    was intimidated b...|       40.859576|       -73.933738|              0|              0|            11|\n",
      "|     1|   A-01-12|           Gray|               White|        ND|Ground Plane|              ND|             Running|             Runs From|                      ND|       40.859989|       -73.934544|              0|              0|            12|\n",
      "|     2|   A-02-01|           Gray|                Gray|        ND|Ground Plane|              ND|             Running|           Indifferent|                      ND|       40.845749|         -73.9407|              0|              0|            13|\n",
      "|     2|   A-02-02|           Gray|            Cinnamon|        ND|Above Ground|              ND|            Foraging|           Indifferent|                      ND|       40.845875|       -73.940808|              2|              2|            14|\n",
      "|     2|   A-02-03|           Gray|            Cinnamon|        ND|Ground Plane|              ND|            Foraging|                    ND|                      ND|       40.845875|       -73.940808|              0|              0|            15|\n",
      "|     2|   A-02-04|           Gray|            Cinnamon|        ND|Ground Plane|              ND|             Running|           Indifferent|                      ND|       40.846088|       -73.940613|              0|              0|            16|\n",
      "|     2|   A-02-05|           Gray|            Cinnamon|        ND|Ground Plane|              ND|             Running|             Runs From|                      ND|       40.846088|       -73.940613|              0|              0|            17|\n",
      "|     2|   A-02-06|           Gray|            Cinnamon|        ND|Ground Plane|              ND|            Foraging|           Indifferent|                      ND|       40.846088|       -73.940613|              0|              0|            18|\n",
      "|     2|   A-02-07|           Gray|                Gray|        ND|Ground Plane|              ND|                  ND|             Runs From|                      ND|       40.846222|        -73.94094|              0|              0|            19|\n",
      "|     2|   A-02-08|           Gray|            Cinnamon|        ND|Ground Plane|              ND|Foraging, Nesting...|           Indifferent|                      ND|       40.846222|        -73.94094|              0|              0|            20|\n",
      "+------+----------+---------------+--------------------+----------+------------+----------------+--------------------+----------------------+------------------------+----------------+-----------------+---------------+---------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Rename columns\n",
    "squirrel_data = squirrel_data.withColumnRenamed(\"SquirrelLatitudeDD.DDDDDD\", \"SquirrelLatitude\") \\\n",
    "                             .withColumnRenamed(\"SquirrelLongitude-DD.DDDDDD\", \"SquirrelLongitude\")\n",
    "\n",
    "# Create a new column \"SquirrelDataID\" with unique identifiers starting from 1\n",
    "squirrel_data = squirrel_data.withColumn(\"SquirrelDataID\", monotonically_increasing_id() + 1)\n",
    "\n",
    "squirrel_data.createOrReplaceTempView(\"View_squirrel_data\")\n",
    "\n",
    "squirrel_data.show(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a35d3b9-c3db-4c4e-87b5-4518369d664d",
   "metadata": {},
   "source": [
    "# Colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8d081c19-e48f-488a-9525-9d6e973230a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a unique list of colors by combining PrimaryFurColor and HighlightsinFurColor\n",
    "Colors = spark.sql(\"\"\"\n",
    "    SELECT EXPLODE(SPLIT(CONCAT_WS(', ', PrimaryFurColor, HighlightsinFurColor), ', ')) AS ColorName\n",
    "    FROM View_squirrel_data\n",
    "\"\"\")\n",
    "\n",
    "# Remove extra white spaces and obtain unique colors\n",
    "Colors = Colors.withColumn(\"ColorName\", trim(Colors[\"ColorName\"]))\n",
    "Colors = Colors.distinct()\n",
    "\n",
    "# Sort and add a row number to the colors\n",
    "window = Window.orderBy(\"ColorName\")\n",
    "Colors = Colors.withColumn(\"ColorID\", row_number().over(window))\n",
    "\n",
    "Colors = Colors.select(\"ColorID\", \"ColorName\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254b632c-9099-436d-aa46-763b2dd7e8a6",
   "metadata": {},
   "source": [
    "### Colors | Table Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e2fea776-0e0f-46ce-81a8-571f391c6e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+\n",
      "|ColorID|ColorName|\n",
      "+-------+---------+\n",
      "|      1|    Black|\n",
      "|      2| Cinnamon|\n",
      "|      3|     Gray|\n",
      "|      4|       ND|\n",
      "|      5|    White|\n",
      "+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create or replace a temporary view from the DataFrame \n",
    "Colors.createOrReplaceTempView(\"View_Colors\")\n",
    "\n",
    "# Define the name of the table containing park conditions\n",
    "table_name = \"colors\"\n",
    "\n",
    "# SQL query to retrieve the maximum ParkConditionID from the database\n",
    "max_cond_sql = \"\"\" SELECT COALESCE(MAX(ColorID), 0) AS max_table_cond_id \n",
    "                   FROM View_table_db\"\"\"\n",
    "\n",
    "# SQL query to identify common rows and add new ones if needed\n",
    "common_rows_sql = \"\"\"\n",
    "                        SELECT\n",
    "                            b.ColorID,\n",
    "                            b.ColorName\n",
    "                        FROM View_table_db b\n",
    "                        UNION ALL\n",
    "                        SELECT\n",
    "                            {max_table_cond_id} + ROW_NUMBER() OVER (ORDER BY a.ColorName) AS ColorID,\n",
    "                            a.ColorName\n",
    "                        FROM View_Colors a\n",
    "                        LEFT JOIN View_table_db b ON trim(a.ColorName) = trim(b.ColorName)\n",
    "                        WHERE b.ColorID IS NULL\n",
    "            \"\"\"\n",
    "\n",
    "# Call the function to update park conditions\n",
    "Colors = update_table_db(spark, jdbc_url, connection_properties, table_name, max_cond_sql, common_rows_sql, Colors)\n",
    "\n",
    "Colors.createOrReplaceTempView(\"View_Colors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f9c0c3-6972-4f11-8f02-9245d23d9b42",
   "metadata": {},
   "source": [
    "# Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4f29a269-80ae-4ec7-b928-ea21c7a96011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique locations and split them by commas\n",
    "Locations = spark.sql(\"\"\"\n",
    "    SELECT EXPLODE(SPLIT(Location, ', ')) AS LocationName\n",
    "    FROM View_squirrel_data\n",
    "    WHERE Location IS NOT NULL\n",
    "\"\"\")\n",
    "\n",
    "# Remove extra white spaces and obtain unique locations\n",
    "Locations = Locations.withColumn(\"LocationName\", trim(Locations[\"LocationName\"]))\n",
    "Locations = Locations.distinct()\n",
    "\n",
    "# Sort and add a row number to the locations\n",
    "window = Window.orderBy(\"LocationName\")\n",
    "Locations = Locations.withColumn(\"LocationID\", F.row_number().over(window))\n",
    "\n",
    "Locations = Locations.select(\"LocationID\", \"LocationName\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588203c3-ca67-4ba0-9d24-a2f074e8476c",
   "metadata": {},
   "source": [
    "### Locations | Table Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "140fcc3f-4e9a-4d51-b56d-66ae5c747726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+\n",
      "|LocationID|     LocationName|\n",
      "+----------+-----------------+\n",
      "|         1|     Above Ground|\n",
      "|         2|     Ground Plane|\n",
      "|         3|               ND|\n",
      "|         4|Specific Location|\n",
      "+----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create or replace a temporary view from the DataFrame \n",
    "Locations.createOrReplaceTempView(\"View_Locations\")\n",
    "\n",
    "# Define the name of the table containing park conditions\n",
    "table_name = \"locations\"\n",
    "\n",
    "# SQL query to retrieve the maximum ParkConditionID from the database\n",
    "max_cond_sql = \"\"\" SELECT COALESCE(MAX(LocationID), 0) AS max_table_cond_id \n",
    "                   FROM View_table_db\"\"\"\n",
    "\n",
    "# SQL query to identify common rows and add new ones if needed\n",
    "common_rows_sql = \"\"\"\n",
    "                        SELECT\n",
    "                            b.LocationID,\n",
    "                            b.LocationName\n",
    "                        FROM View_table_db b\n",
    "                        UNION ALL\n",
    "                        SELECT\n",
    "                            {max_table_cond_id} + ROW_NUMBER() OVER (ORDER BY a.LocationName) AS LocationID,\n",
    "                            a.LocationName\n",
    "                        FROM View_Locations a\n",
    "                        LEFT JOIN View_table_db b ON trim(a.LocationName) = trim(b.LocationName)\n",
    "                        WHERE b.LocationID IS NULL\n",
    "            \"\"\"\n",
    "\n",
    "# Call the function to update park conditions\n",
    "Locations = update_table_db(spark, jdbc_url, connection_properties, table_name, max_cond_sql, common_rows_sql, Locations)\n",
    "\n",
    "Locations.createOrReplaceTempView(\"View_Locations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137359b0-6528-404a-99af-f48c5dfc38e5",
   "metadata": {},
   "source": [
    "# Activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3c6a5e92-fce5-417d-b5ec-dd4b9db7c9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique activities and split them by commas\n",
    "Activities = spark.sql(\"\"\"\n",
    "    SELECT EXPLODE(SPLIT(Activities, ', ')) AS ActivityName\n",
    "    FROM View_squirrel_data\n",
    "    WHERE Activities IS NOT NULL\n",
    "\"\"\")\n",
    "\n",
    "# Remove extra white spaces from activity names\n",
    "Activities = Activities.withColumn(\"ActivityName\", trim(Activities[\"ActivityName\"]))\n",
    "\n",
    "# Replace text within parentheses and the parentheses themselves with an empty string\n",
    "Activities = Activities.withColumn('ActivityName', trim(regexp_replace('ActivityName', r'\\(.*?\\)', '')))\n",
    "\n",
    "# Obtain unique activities\n",
    "Activities = Activities.distinct()\n",
    "\n",
    "# Sort and add a row number to the activities\n",
    "window = Window.orderBy(\"ActivityName\")\n",
    "Activities = Activities.withColumn(\"ActivityID\", F.row_number().over(window))\n",
    "\n",
    "# Selecting the unique activity identifiers and their names\n",
    "Activities = Activities.select(\"ActivityID\", \"ActivityName\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c159da-0983-48d4-9d0d-b9a19c964771",
   "metadata": {},
   "source": [
    "### Activities | Table Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6e81a0b6-2b1a-401d-a522-4fc75d247778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+\n",
      "|ActivityID|        ActivityName|\n",
      "+----------+--------------------+\n",
      "|         1|Balancing on fencing|\n",
      "|         2|             Burying|\n",
      "|         3|             Chasing|\n",
      "|         4|          Chattering|\n",
      "|         5|             Chillin|\n",
      "|         6|            Chilling|\n",
      "|         7|            Cleaning|\n",
      "|         8|            Climbing|\n",
      "|         9|      Climbing fence|\n",
      "|        10|      Defending tree|\n",
      "|        11|             Digging|\n",
      "|        12|   Digging something|\n",
      "|        13|      Ear scratching|\n",
      "|        14|              Eating|\n",
      "|        15|            Foraging|\n",
      "|        16|          Frolicking|\n",
      "|        17|            Grooming|\n",
      "|        18|            Guarding|\n",
      "|        19|Hangin  with #13 ...|\n",
      "|        20|             Hanging|\n",
      "+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create or replace a temporary view from the DataFrame \n",
    "Activities.createOrReplaceTempView(\"View_Activities\")\n",
    "\n",
    "# Define the name of the table containing park conditions\n",
    "table_name = \"activities\"\n",
    "\n",
    "# SQL query to retrieve the maximum ParkConditionID from the database\n",
    "max_cond_sql = \"\"\" SELECT COALESCE(MAX(ActivityID), 0) AS max_table_cond_id \n",
    "                   FROM View_table_db\"\"\"\n",
    "\n",
    "# SQL query to identify common rows and add new ones if needed\n",
    "common_rows_sql = \"\"\"\n",
    "                        SELECT\n",
    "                            b.ActivityID,\n",
    "                            b.ActivityName\n",
    "                        FROM View_table_db b\n",
    "                        UNION ALL\n",
    "                        SELECT\n",
    "                            {max_table_cond_id} + ROW_NUMBER() OVER (ORDER BY a.ActivityName) AS ActivityID,\n",
    "                            a.ActivityName\n",
    "                        FROM View_Activities a\n",
    "                        LEFT JOIN View_table_db b ON trim(a.ActivityName) = trim(b.ActivityName)\n",
    "                        WHERE b.ActivityID IS NULL\n",
    "            \"\"\"\n",
    "\n",
    "# Call the function to update park conditions\n",
    "Activities = update_table_db(spark, jdbc_url, connection_properties, table_name, max_cond_sql, common_rows_sql, Activities)\n",
    "\n",
    "Activities.createOrReplaceTempView(\"View_Activities\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe37fb68-d4b3-4e23-b60f-ccc28ae26842",
   "metadata": {},
   "source": [
    "# Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aaa2bd63-8486-4d8f-978a-3cd4e3b29b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining unique interactions and splitting them by commas\n",
    "Interactions = spark.sql(\"\"\"\n",
    "    SELECT EXPLODE(SPLIT(InteractionswithHumans, ', ')) AS InteractionName\n",
    "    FROM View_squirrel_data\n",
    "    WHERE InteractionswithHumans IS NOT NULL\n",
    "\"\"\")\n",
    "\n",
    "# Removing additional whitespace and obtaining unique interactions\n",
    "Interactions = Interactions.withColumn(\"InteractionName\", trim(Interactions[\"InteractionName\"]))\n",
    "\n",
    "# Replacing text within parentheses and the parentheses themselves with an empty string\n",
    "Interactions = Interactions.withColumn('InteractionName', trim(regexp_replace('InteractionName', r'\\(.*?\\)', '')))\n",
    "\n",
    "# Obtaining unique interactions\n",
    "Interactions = Interactions.distinct()\n",
    "\n",
    "# Sorting and adding a row number to the interactions\n",
    "window = Window.orderBy(\"InteractionName\")\n",
    "Interactions = Interactions.withColumn(\"InteractionID\", F.row_number().over(window))\n",
    "\n",
    "Interactions = Interactions.select(\"InteractionID\", \"InteractionName\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989e0998-1a1d-472b-b8d8-26e7ca544901",
   "metadata": {},
   "source": [
    "### Interactions | Table Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "04b4ed26-b0d2-4350-b8e2-8a24ddb064d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+\n",
      "|InteractionID|     InteractionName|\n",
      "+-------------+--------------------+\n",
      "|            1|          Approaches|\n",
      "|            2|         Cautious of|\n",
      "|            3|           Defensive|\n",
      "|            4|            Friendly|\n",
      "|            5|         Indifferent|\n",
      "|            6|       Interested in|\n",
      "|            7|                  ND|\n",
      "|            8|    Okay with people|\n",
      "|            9|Preoccupied by HAAWK|\n",
      "|           10|           Runs From|\n",
      "|           11|  Skittish to humans|\n",
      "|           12|             Staring|\n",
      "|           13|Watches us from tree|\n",
      "|           14|            Watching|\n",
      "|           15|Watching us from ...|\n",
      "|           16|watches us in sho...|\n",
      "|           17|            watchful|\n",
      "|           18|         watching us|\n",
      "+-------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create or replace a temporary view from the DataFrame \n",
    "Interactions.createOrReplaceTempView(\"View_Interactions\")\n",
    "\n",
    "# Define the name of the table containing park conditions\n",
    "table_name = \"interactions\"\n",
    "\n",
    "# SQL query to retrieve the maximum ParkConditionID from the database\n",
    "max_cond_sql = \"\"\" SELECT COALESCE(MAX(InteractionID), 0) AS max_table_cond_id \n",
    "                   FROM View_table_db\"\"\"\n",
    "\n",
    "# SQL query to identify common rows and add new ones if needed\n",
    "common_rows_sql = \"\"\"\n",
    "                        SELECT\n",
    "                            b.InteractionID,\n",
    "                            b.InteractionName\n",
    "                        FROM View_table_db b\n",
    "                        UNION ALL\n",
    "                        SELECT\n",
    "                            {max_table_cond_id} + ROW_NUMBER() OVER (ORDER BY a.InteractionName) AS InteractionID,\n",
    "                            a.InteractionName\n",
    "                        FROM View_Interactions a\n",
    "                        LEFT JOIN View_table_db b ON trim(a.InteractionName) = trim(b.InteractionName)\n",
    "                        WHERE b.InteractionID IS NULL\n",
    "            \"\"\"\n",
    "\n",
    "# Call the function to update park conditions\n",
    "Interactions = update_table_db(spark, jdbc_url, connection_properties, table_name, max_cond_sql, common_rows_sql, Interactions)\n",
    "\n",
    "Interactions.createOrReplaceTempView(\"View_Interactions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0733462-35c9-4759-b1ff-0a3123926e86",
   "metadata": {},
   "source": [
    "# Squirrels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fb1bf329-edb5-4643-bd96-d4db31a97040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting squirrel data with joined color IDs\n",
    "Squirrels = spark.sql(\"\"\"\n",
    "    SELECT a.SquirrelDataID, a.SquirrelID, a.ParkID,  b.ColorID as SquirrelPrimFurColorID, c.ColorID as SquirrelHighFurColorID, a.ColorNotes as SquirrelColorNotes, SpecificLocation as SquirrelSpecificLocation,\n",
    "           OtherNotesorObservations as SquirrelObservations, a.SquirrelLatitude, a.SquirrelLongitude, a.Min_Height_Feet as SquirrelMinHeightFeet,\n",
    "           a.Max_Height_Feet as SquirrelMaxHeightFeet\n",
    "    FROM View_squirrel_data a LEFT JOIN View_Colors b on trim(a.PrimaryFurColor)      = trim(b.ColorName)\n",
    "                              LEFT JOIN View_Colors c on trim(a.HighlightsinFurColor) = trim(c.ColorName)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45c2b15-7713-4a85-b099-a76e3ea07a93",
   "metadata": {},
   "source": [
    "### Squirrels | Table Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a83aea2d-7449-495c-9bbe-4e4f279a1413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+------+----------------------+----------------------+------------------+------------------------+--------------------+----------------+-----------------+---------------------+---------------------+\n",
      "|SquirrelDataID|SquirrelID|ParkID|SquirrelPrimFurColorID|SquirrelHighFurColorID|SquirrelColorNotes|SquirrelSpecificLocation|SquirrelObservations|SquirrelLatitude|SquirrelLongitude|SquirrelMinHeightFeet|SquirrelMaxHeightFeet|\n",
      "+--------------+----------+------+----------------------+----------------------+------------------+------------------------+--------------------+----------------+-----------------+---------------------+---------------------+\n",
      "|             1|   A-01-01|     1|                     3|                     5|                ND|                      ND|                  ND|        40.85941|       -73.933936|                    0|                    0|\n",
      "|             2|   A-01-02|     1|                     3|                     5|                ND|                      ND|        Looks skinny|       40.859436|       -73.933937|                    0|                    0|\n",
      "|             3|   A-01-03|     1|                     3|                     5|                ND|                      ND|                  ND|       40.859416|       -73.933894|                    0|                    0|\n",
      "|             4|   A-01-04|     1|                     3|                     5|                ND|                      ND|                  ND|       40.859418|       -73.933895|                    0|                    0|\n",
      "|             5|   A-01-05|     1|                     3|                     2|                ND|                      ND|       She left food|       40.859493|        -73.93359|                    0|                    0|\n",
      "|             6|   A-01-06|     1|                     3|                     2|                ND|                      ND|                  ND|       40.860825|       -73.932871|                    0|                    0|\n",
      "|             7|   A-01-07|     1|                     3|                     5|                ND|                      ND|                  ND|       40.860225|       -73.933143|                    0|                    0|\n",
      "|             8|   A-01-08|     1|                     1|                     3|                ND|                      ND|                  ND|       40.859965|       -73.933412|                   10|                   10|\n",
      "|             9|   A-01-09|     1|                     3|                     5|                ND|                      ND|                  ND|       40.859892|       -73.933326|                    0|                    0|\n",
      "|            10|   A-01-10|     1|                     3|                     5|                ND|                      ND|                  ND|       40.859636|       -73.933717|                    0|                    0|\n",
      "|            11|   A-01-11|     1|                     3|                     1|                ND|                      ND|was intimidated b...|       40.859576|       -73.933738|                    0|                    0|\n",
      "|            12|   A-01-12|     1|                     3|                     5|                ND|                      ND|                  ND|       40.859989|       -73.934544|                    0|                    0|\n",
      "|            13|   A-02-01|     2|                     3|                     3|                ND|                      ND|                  ND|       40.845749|         -73.9407|                    0|                    0|\n",
      "|            14|   A-02-02|     2|                     3|                     2|                ND|                      ND|                  ND|       40.845875|       -73.940808|                    2|                    2|\n",
      "|            15|   A-02-03|     2|                     3|                     2|                ND|                      ND|                  ND|       40.845875|       -73.940808|                    0|                    0|\n",
      "|            16|   A-02-04|     2|                     3|                     2|                ND|                      ND|                  ND|       40.846088|       -73.940613|                    0|                    0|\n",
      "|            17|   A-02-05|     2|                     3|                     2|                ND|                      ND|                  ND|       40.846088|       -73.940613|                    0|                    0|\n",
      "|            18|   A-02-06|     2|                     3|                     2|                ND|                      ND|                  ND|       40.846088|       -73.940613|                    0|                    0|\n",
      "|            19|   A-02-07|     2|                     3|                     3|                ND|                      ND|                  ND|       40.846222|        -73.94094|                    0|                    0|\n",
      "|            20|   A-02-08|     2|                     3|                     2|                ND|                      ND|                  ND|       40.846222|        -73.94094|                    0|                    0|\n",
      "+--------------+----------+------+----------------------+----------------------+------------------+------------------------+--------------------+----------------+-----------------+---------------------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create or replace a temporary view from the DataFrame \n",
    "Squirrels.createOrReplaceTempView(\"View_Squirrels\")\n",
    "\n",
    "# Define the name of the table containing park conditions\n",
    "table_name = \"squirrels\"\n",
    "\n",
    "# SQL query to retrieve the maximum ParkConditionID from the database\n",
    "max_cond_sql = \"\"\" SELECT COALESCE(MAX(SquirrelDataID), 0) AS max_table_cond_id \n",
    "                   FROM View_table_db\"\"\"\n",
    "\n",
    "# SQL query to identify common rows and add new ones if needed\n",
    "common_rows_sql = \"\"\"\n",
    "                        SELECT\n",
    "                            b.SquirrelDataID, \n",
    "                            b.SquirrelID, \n",
    "                            b.ParkID, \n",
    "                            b.SquirrelPrimFurColorID, \n",
    "                            b.SquirrelHighFurColorID, \n",
    "                            b.SquirrelColorNotes, \n",
    "                            b.SquirrelSpecificLocation, \n",
    "                            b.SquirrelObservations, \n",
    "                            b.SquirrelLatitude, \n",
    "                            b.SquirrelLongitude, \n",
    "                            b.SquirrelMinHeightFeet, \n",
    "                            b.SquirrelMaxHeightFeet\n",
    "                        FROM View_table_db b\n",
    "                        UNION ALL\n",
    "                        SELECT\n",
    "                            {max_table_cond_id} + ROW_NUMBER() OVER (ORDER BY a.SquirrelDataID) AS SquirrelDataID,\n",
    "                            a.SquirrelID, \n",
    "                            a.ParkID, \n",
    "                            a.SquirrelPrimFurColorID, \n",
    "                            a.SquirrelHighFurColorID, \n",
    "                            a.SquirrelColorNotes, \n",
    "                            a.SquirrelSpecificLocation, \n",
    "                            a.SquirrelObservations, \n",
    "                            a.SquirrelLatitude, \n",
    "                            a.SquirrelLongitude, \n",
    "                            a.SquirrelMinHeightFeet, \n",
    "                            a.SquirrelMaxHeightFeet\n",
    "                        FROM View_Squirrels a\n",
    "                        LEFT JOIN View_table_db b ON trim(a.SquirrelID)         = trim(b.SquirrelID)         AND\n",
    "                                                     a.ParkID                   = b.ParkID                   AND   \n",
    "                                                     a.SquirrelPrimFurColorID   = b.SquirrelPrimFurColorID   AND\n",
    "                                                     a.SquirrelHighFurColorID   = b.SquirrelHighFurColorID   AND\n",
    "                                                     a.SquirrelColorNotes       = b.SquirrelColorNotes       AND\n",
    "                                                     a.SquirrelSpecificLocation = b.SquirrelSpecificLocation AND\n",
    "                                                     a.SquirrelObservations     = b.SquirrelObservations     AND \n",
    "                                                     a.SquirrelLatitude         = b.SquirrelLatitude         AND\n",
    "                                                     a.SquirrelLongitude        = b.SquirrelLongitude        AND\n",
    "                                                     a.SquirrelMinHeightFeet    = b.SquirrelMinHeightFeet    AND\n",
    "                                                     a.SquirrelMaxHeightFeet    = b.SquirrelMaxHeightFeet \n",
    "                        WHERE b.SquirrelID IS NULL\n",
    "            \"\"\"\n",
    "\n",
    "# Call the function to update park conditions\n",
    "Squirrels = update_table_db(spark, jdbc_url, connection_properties, table_name, max_cond_sql, common_rows_sql, Squirrels)\n",
    "\n",
    "Squirrels.createOrReplaceTempView(\"View_Squirrels\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38665076-5ff7-4759-a38f-a18ca5cbcdc0",
   "metadata": {},
   "source": [
    "# SquirrelHumanInteractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ee751401-0c4d-4f8a-bfa6-a386162e15fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieving data from the view and exploding the InteractionswithHumans column\n",
    "SquirrelHumanInteractions = spark.sql(\"\"\"\n",
    "    SELECT SquirrelDataID, ParkID, SquirrelID, explode(split(trim(InteractionswithHumans), ', ')) AS InteractionswithHumans\n",
    "    FROM View_squirrel_data\n",
    "\"\"\")\n",
    "\n",
    "# Extracting text within parentheses into a new column\n",
    "SquirrelHumanInteractions = SquirrelHumanInteractions.withColumn(\"SquirrelHumanInteractionObs\", regexp_extract(col(\"InteractionswithHumans\"), \"\\(([^)]*)\\)\", 1))\n",
    "\n",
    "# Removing parentheses from the InteractionswithHumans column\n",
    "SquirrelHumanInteractions = SquirrelHumanInteractions.withColumn(\"InteractionswithHumans\", regexp_replace(col(\"InteractionswithHumans\"), \"\\([^)]*\\)\", \"\"))\n",
    "\n",
    "# Replacing \"xxzxx\" with commas in the SquirrelHumanInteractionObs column\n",
    "SquirrelHumanInteractions = SquirrelHumanInteractions.withColumn(\"SquirrelHumanInteractionObs\", regexp_replace(col(\"SquirrelHumanInteractionObs\"), \"xxzxx\", \", \"))\n",
    "\n",
    "# Creating a new column \"SquirrelHumanInteractionID\" with unique identifiers starting from 1\n",
    "SquirrelHumanInteractions = SquirrelHumanInteractions.withColumn(\"SquirrelHumanInteractionID\", monotonically_increasing_id() + 1)\n",
    "\n",
    "SquirrelHumanInteractions.createOrReplaceTempView(\"View_SquirrelHumanInteractions\")\n",
    "\n",
    "SquirrelHumanInteractions = spark.sql(\"\"\"\n",
    "    SELECT a.SquirrelHumanInteractionID, a.SquirrelDataID, a.SquirrelID, b.InteractionID, a.SquirrelHumanInteractionObs\n",
    "    FROM View_SquirrelHumanInteractions a left join View_Interactions b on trim(a.InteractionswithHumans) = trim(b.InteractionName)\n",
    "    ORDER BY a.SquirrelHumanInteractionID\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e032470d-46af-4d3a-a7de-8fe265b7ffe6",
   "metadata": {},
   "source": [
    "### SquirrelHumanInteractions | Table Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d9405397-05cb-4ea3-88bc-348f60c8cb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+--------------+----------+-------------+---------------------------+\n",
      "|SquirrelHumanInteractionID|SquirrelDataID|SquirrelID|InteractionID|SquirrelHumanInteractionObs|\n",
      "+--------------------------+--------------+----------+-------------+---------------------------+\n",
      "|                         1|             1|   A-01-01|            5|                           |\n",
      "|                         2|             2|   A-01-02|            5|                           |\n",
      "|                         3|             3|   A-01-03|            5|                           |\n",
      "|                         4|             4|   A-01-04|            5|                           |\n",
      "|                         5|             5|   A-01-05|            5|                           |\n",
      "|                         6|             6|   A-01-06|            5|                           |\n",
      "|                         7|             7|   A-01-07|            5|                           |\n",
      "|                         8|             8|   A-01-08|           10|                           |\n",
      "|                         9|             9|   A-01-09|            5|                           |\n",
      "|                        10|            10|   A-01-10|            5|                           |\n",
      "|                        11|            11|   A-01-11|            5|                           |\n",
      "|                        12|            12|   A-01-12|           10|                           |\n",
      "|                        13|            13|   A-02-01|            5|                           |\n",
      "|                        14|            14|   A-02-02|            5|                           |\n",
      "|                        15|            15|   A-02-03|            7|                           |\n",
      "|                        16|            16|   A-02-04|            5|                           |\n",
      "|                        17|            17|   A-02-05|           10|                           |\n",
      "|                        18|            18|   A-02-06|            5|                           |\n",
      "|                        19|            19|   A-02-07|           10|                           |\n",
      "|                        20|            20|   A-02-08|            5|                           |\n",
      "+--------------------------+--------------+----------+-------------+---------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create or replace a temporary view from the DataFrame \n",
    "SquirrelHumanInteractions.createOrReplaceTempView(\"View_SquirrelHumanInteractions\")\n",
    "\n",
    "# Define the name of the table containing park conditions\n",
    "table_name = \"squirrelhumaninteractions\"\n",
    "\n",
    "# SQL query to retrieve the maximum ParkConditionID from the database\n",
    "max_cond_sql = \"\"\" SELECT COALESCE(MAX(SquirrelHumanInteractionID), 0) AS max_table_cond_id \n",
    "                   FROM View_table_db\"\"\"\n",
    "\n",
    "# SQL query to identify common rows and add new ones if needed\n",
    "common_rows_sql = \"\"\"\n",
    "                        SELECT\n",
    "                            b.SquirrelHumanInteractionID,\n",
    "                            b.SquirrelDataID,\n",
    "                            b.SquirrelID,\n",
    "                            b.InteractionID,\n",
    "                            b.SquirrelHumanInteractionObs\n",
    "                        FROM View_table_db b\n",
    "                        UNION ALL\n",
    "                        SELECT\n",
    "                            {max_table_cond_id} + ROW_NUMBER() OVER (ORDER BY a.SquirrelID) AS SquirrelHumanInteractionID,\n",
    "                            a.SquirrelDataID,\n",
    "                            a.SquirrelID,\n",
    "                            a.InteractionID,\n",
    "                            a.SquirrelHumanInteractionObs\n",
    "                        FROM View_SquirrelHumanInteractions a\n",
    "                        LEFT JOIN View_table_db b ON trim(a.SquirrelID) = trim(b.SquirrelID) AND\n",
    "                                                     a.SquirrelDataID   = b.SquirrelDataID   AND\n",
    "                                                     a.SquirrelID       = b.SquirrelID       AND\n",
    "                                                     a.InteractionID    = b.InteractionID    AND\n",
    "                                                     trim(a.SquirrelHumanInteractionObs) = trim(b.SquirrelHumanInteractionObs)\n",
    "                        WHERE b.SquirrelDataID IS NULL\n",
    "            \"\"\"\n",
    "\n",
    "# Call the function to update park conditions\n",
    "SquirrelHumanInteractions = update_table_db(spark, jdbc_url, connection_properties, table_name, max_cond_sql, common_rows_sql, SquirrelHumanInteractions)\n",
    "\n",
    "SquirrelHumanInteractions.createOrReplaceTempView(\"SquirrelHumanInteractions\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8220cc71-7b8a-4fad-9a5b-0b66a9ec244f",
   "metadata": {},
   "source": [
    "# SquirelLocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fc0b21da-99e2-41a3-835c-47fd1cefaa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieving data from the view and exploding the Location column\n",
    "SquirrelLocations = spark.sql(\"\"\"\n",
    "    SELECT SquirrelDataID, ParkID, SquirrelID, explode(split(trim(Location), ', ')) AS SquirrelLocations\n",
    "    FROM View_squirrel_data\n",
    "\"\"\")\n",
    "# SquirrelLocations.show(20)\n",
    "\n",
    "# Extracting text within parentheses into a new column\n",
    "SquirrelLocations = SquirrelLocations.withColumn(\"SquirrelLocationObs\", regexp_extract(col(\"SquirrelLocations\"), \"\\(([^)]*)\\)\", 1))\n",
    "\n",
    "# Removing parentheses from the Location column\n",
    "SquirrelLocations = SquirrelLocations.withColumn(\"SquirrelLocations\", regexp_replace(col(\"SquirrelLocations\"), \"\\([^)]*\\)\", \"\"))\n",
    "# SquirrelLocations.show(20)\n",
    "\n",
    "# Replacing \"xxzxx\" with commas in the SquirrelLocationObs column\n",
    "SquirrelLocations = SquirrelLocations.withColumn(\"SquirrelLocationObs\", regexp_replace(col(\"SquirrelLocationObs\"), \"xxzxx\", \", \"))\n",
    "\n",
    "# Creating a new column \"SquirrelLocationID\" with unique identifiers\n",
    "SquirrelLocations = SquirrelLocations.withColumn(\"SquirrelLocationID\", monotonically_increasing_id() + 1)\n",
    "\n",
    "SquirrelLocations.createOrReplaceTempView(\"View_SquirrelLocations\")\n",
    "\n",
    "SquirrelLocations = spark.sql(\"\"\"\n",
    "    SELECT a.SquirrelLocationID, a.SquirrelDataID, b.LocationID, a.SquirrelLocationObs\n",
    "    FROM View_SquirrelLocations a left join View_Locations b on trim(a.SquirrelLocations) = trim(b.LocationName)\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fa43e2-119d-47b9-acce-ef8d00c45d2f",
   "metadata": {},
   "source": [
    "### SquirelLocations | Table Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ba4665e7-783b-48cb-848c-cbb9a2f2b4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------+----------+-------------------+\n",
      "|SquirrelLocationID|SquirrelDataID|LocationID|SquirrelLocationObs|\n",
      "+------------------+--------------+----------+-------------------+\n",
      "|                 1|             1|         2|                   |\n",
      "|                 2|             2|         2|                   |\n",
      "|                 3|             3|         2|                   |\n",
      "|                 4|             4|         2|                   |\n",
      "|                 5|             5|         2|                   |\n",
      "|                 6|             6|         2|                   |\n",
      "|                 7|             7|         2|                   |\n",
      "|                 8|             8|         1|                   |\n",
      "|                 9|             9|         2|                   |\n",
      "|                10|            10|         2|                   |\n",
      "|                11|            11|         2|                   |\n",
      "|                12|            12|         2|                   |\n",
      "|                13|            13|         2|                   |\n",
      "|                14|            14|         1|                   |\n",
      "|                15|            15|         2|                   |\n",
      "|                16|            16|         2|                   |\n",
      "|                17|            17|         2|                   |\n",
      "|                18|            18|         2|                   |\n",
      "|                19|            19|         2|                   |\n",
      "|                20|            20|         2|                   |\n",
      "+------------------+--------------+----------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create or replace a temporary view from the DataFrame \n",
    "SquirrelLocations.createOrReplaceTempView(\"View_SquirrelLocations\")\n",
    "\n",
    "# Define the name of the table containing park conditions\n",
    "table_name = \"squirrellocations\"\n",
    "\n",
    "# SQL query to retrieve the maximum ParkConditionID from the database\n",
    "max_cond_sql = \"\"\" SELECT COALESCE(MAX(SquirrelLocationID), 0) AS max_table_cond_id \n",
    "                   FROM View_table_db\"\"\"\n",
    "\n",
    "# SQL query to identify common rows and add new ones if needed\n",
    "common_rows_sql = \"\"\"\n",
    "                        SELECT\n",
    "                            b.SquirrelLocationID,\n",
    "                            b.SquirrelDataID,\n",
    "                            b.LocationID,\n",
    "                            b.SquirrelLocationObs\n",
    "                        FROM View_table_db b\n",
    "                        UNION ALL\n",
    "                        SELECT\n",
    "                            {max_table_cond_id} + ROW_NUMBER() OVER (ORDER BY a.SquirrelDataID) AS SquirrelLocationID,\n",
    "                            a.SquirrelDataID,\n",
    "                            a.LocationID,\n",
    "                            a.SquirrelLocationObs\n",
    "                        FROM View_SquirrelLocations a\n",
    "                        LEFT JOIN View_table_db b ON a.SquirrelLocationID        = b.SquirrelDataID      AND\n",
    "                                                     a.LocationID                = a.LocationID          AND\n",
    "                                                     trim(a.SquirrelLocationObs) = trim(b.SquirrelLocationObs) \n",
    "                                                \n",
    "                        WHERE b.SquirrelLocationID IS NULL\n",
    "            \"\"\"\n",
    "\n",
    "# Call the function to update park conditions\n",
    "SquirrelLocations = update_table_db(spark, jdbc_url, connection_properties, table_name, max_cond_sql, common_rows_sql, SquirrelLocations)\n",
    "\n",
    "SquirrelLocations.createOrReplaceTempView(\"SquirrelLocations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddd24b2-4b3b-47cf-96e9-dcab698e5197",
   "metadata": {},
   "source": [
    "# SquirrelActivities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bf426f13-d7ad-4c25-804d-2e50637c7e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieving data from the view and exploding the Activities column\n",
    "SquirrelActivities = spark.sql(\"\"\"\n",
    "    SELECT SquirrelDataID, ParkID, SquirrelID, explode(split(trim(Activities), ', ')) AS SquirrelActivities\n",
    "    FROM View_squirrel_data\n",
    "\"\"\")\n",
    "\n",
    "# Extracting text within parentheses into a new column\n",
    "SquirrelActivities = SquirrelActivities.withColumn(\"SquirrelActivityObs\", regexp_extract(col(\"SquirrelActivities\"), \"\\(([^)]*)\\)\", 1))\n",
    "\n",
    "# Removing parentheses from the Activities column\n",
    "SquirrelActivities = SquirrelActivities.withColumn(\"SquirrelActivities\", regexp_replace(col(\"SquirrelActivities\"), \"\\([^)]*\\)\", \"\"))\n",
    "\n",
    "\n",
    "# Replacing \"xxzxx\" with commas in the SquirrelActivityObs column\n",
    "SquirrelActivities = SquirrelActivities.withColumn(\"SquirrelActivityObs\", regexp_replace(col(\"SquirrelActivityObs\"), \"xxzxx\", \", \"))\n",
    "\n",
    "# Creating a new column \"SquirrelActivityID\" with unique identifiers\n",
    "SquirrelActivities = SquirrelActivities.withColumn(\"SquirrelActivityID\", monotonically_increasing_id() + 1)\n",
    "\n",
    "SquirrelActivities.createOrReplaceTempView(\"View_SquirrelActivities\")\n",
    "\n",
    "SquirrelActivities = spark.sql(\"\"\"\n",
    "    SELECT a.SquirrelActivityID, a.SquirrelDataID, b.ActivityID, a.SquirrelActivityObs\n",
    "    FROM View_SquirrelActivities a left join View_Activities b on trim(a.SquirrelActivities) = trim(b.ActivityName)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eefaf76-76d8-46a2-ae4a-d0e2a8fc5673",
   "metadata": {},
   "source": [
    "### SquirrelActivities | Table Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "018847df-4858-4059-acf7-f76ea44b77a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------+----------+-------------------+\n",
      "|SquirrelActivityID|SquirrelDataID|ActivityID|SquirrelActivityObs|\n",
      "+------------------+--------------+----------+-------------------+\n",
      "|                 1|             1|        15|                   |\n",
      "|                 2|             2|        15|                   |\n",
      "|                 3|             3|        14|                   |\n",
      "|                 4|             3|        12|                   |\n",
      "|                 5|             4|        32|                   |\n",
      "|                 6|             5|        32|                   |\n",
      "|                 7|             5|        14|                   |\n",
      "|                 8|             6|         8|                   |\n",
      "|                 9|             7|        15|                   |\n",
      "|                10|             8|         8|                   |\n",
      "|                11|             9|        15|                   |\n",
      "|                12|            10|        14|                   |\n",
      "|                13|            10|        11|                   |\n",
      "|                14|            11|        14|                   |\n",
      "|                15|            11|        11|                   |\n",
      "|                16|            12|        32|                   |\n",
      "|                17|            13|        32|                   |\n",
      "|                18|            14|        15|                   |\n",
      "|                19|            15|        15|                   |\n",
      "|                20|            16|        32|                   |\n",
      "+------------------+--------------+----------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create or replace a temporary view from the DataFrame \n",
    "SquirrelActivities.createOrReplaceTempView(\"View_SquirrelActivities\")\n",
    "\n",
    "# Define the name of the table containing park conditions\n",
    "table_name = \"squirrelactivities\"\n",
    "\n",
    "# SQL query to retrieve the maximum ParkConditionID from the database\n",
    "max_cond_sql = \"\"\" SELECT COALESCE(MAX(SquirrelActivityID), 0) AS max_table_cond_id \n",
    "                   FROM View_table_db\"\"\"\n",
    "\n",
    "# SQL query to identify common rows and add new ones if needed\n",
    "common_rows_sql = \"\"\"\n",
    "                        SELECT\n",
    "                            b.SquirrelActivityID,\n",
    "                            b.SquirrelDataID,\n",
    "                            b.ActivityID,\n",
    "                            b.SquirrelActivityObs\n",
    "                        FROM View_table_db b\n",
    "                        UNION ALL\n",
    "                        SELECT\n",
    "                            {max_table_cond_id} + ROW_NUMBER() OVER (ORDER BY a.SquirrelDataID) AS SquirrelActivityID,\n",
    "                            a.SquirrelDataID,\n",
    "                            a.ActivityID,\n",
    "                            a.SquirrelActivityObs\n",
    "                        FROM View_SquirrelActivities a\n",
    "                        LEFT JOIN View_table_db b ON a.SquirrelDataID            = b.SquirrelDataID      AND\n",
    "                                                     a.ActivityID                = a.ActivityID          AND\n",
    "                                                     trim(b.SquirrelActivityObs) = trim(b.SquirrelActivityObs) \n",
    "                                                \n",
    "                        WHERE b.SquirrelActivityID IS NULL\n",
    "            \"\"\"\n",
    "\n",
    "# Call the function to update park conditions\n",
    "SquirrelActivities = update_table_db(spark, jdbc_url, connection_properties, table_name, max_cond_sql, common_rows_sql, SquirrelActivities)\n",
    "\n",
    "SquirrelActivities.createOrReplaceTempView(\"SquirrelLocations\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaa889e-e6c7-4660-9010-c87b83f19c4f",
   "metadata": {},
   "source": [
    "# Query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02fde52-01db-4c99-b9da-279fce3912f0",
   "metadata": {},
   "source": [
    "## 1. How many squirrels are there in each Park?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0f4f0d0f-4b19-4d80-91e7-9352a5bf538b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+------------+\n",
      "|ParkID|            ParkName|qty_squirrel|\n",
      "+------+--------------------+------------+\n",
      "|     1|     Fort Tryon Park|          12|\n",
      "|     2|  J Hood Wright Park|          24|\n",
      "|     3|     Highbridge Park|          16|\n",
      "|     4|    St Nicholas Park|          15|\n",
      "|     5|      Riverside Park|          28|\n",
      "|     6|  Marcus Garvey Park|          34|\n",
      "|     7| Madison Square Park|          11|\n",
      "|     8|   Union Square Park|          16|\n",
      "|     9|Stuyvesant Square...|          25|\n",
      "|    10|Washington Square...|          51|\n",
      "|    11|Tompkins Square Park|          59|\n",
      "|    12|John V Lindsay Ea...|          12|\n",
      "|    14|         Seward Park|           7|\n",
      "|    15|  Corlears Hook Park|          16|\n",
      "|    16|       Columbus Park|           4|\n",
      "|    18|       Teardrop Park|           1|\n",
      "|    19|      City Hall Park|          18|\n",
      "|    20|        Battery Park|          26|\n",
      "|    21| Msgr McGolrick Park|          14|\n",
      "|    22|       McCarren Park|          44|\n",
      "+------+--------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL query\n",
    "query = \"\"\"\n",
    "    (SELECT q.\"ParkID\", p.\"ParkName\", COUNT(*) AS qty_squirrel\n",
    "    FROM (SELECT \"ParkID\", \"SquirrelID\"\n",
    "          FROM squirrels\n",
    "          GROUP BY \"ParkID\", \"SquirrelID\"\n",
    "          ORDER BY \"ParkID\") q\n",
    "    LEFT JOIN parks p ON q.\"ParkID\" = p.\"ParkID\"\n",
    "    GROUP BY q.\"ParkID\", p.\"ParkName\"\n",
    "    ORDER BY q.\"ParkID\") AS subquery\n",
    "\"\"\"\n",
    "\n",
    "# Reading data\n",
    "df = spark.read.jdbc(url=jdbc_url, table=query, properties=connection_properties)\n",
    "df.show()\n",
    "\n",
    "df.toPandas().to_csv('output/query_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0bb101-2443-4427-9c95-9d5232e1e43e",
   "metadata": {},
   "source": [
    "## 2. How many squirrels are there in each Borough?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e2c4299b-a918-405e-a44e-8738dcc766dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+------------+\n",
      "|AreaID|         AreaName|qty_squirrel|\n",
      "+------+-----------------+------------+\n",
      "|     1|  UPPER MANHATTAN|         129|\n",
      "|     2|CENTRAL MANHATTAN|         174|\n",
      "|     3|  LOWER MANHATTAN|          72|\n",
      "|     4|         BROOKLYN|          58|\n",
      "+------+-----------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL query\n",
    "query = \"\"\"\n",
    "    (select q.\"AreaID\", a.\"AreaName\", count(*) as qty_squirrel\n",
    "    from (select \"AreaID\", \"SquirrelID\"\n",
    "          from squirrels s left join parks p on s.\"ParkID\" = p.\"ParkID\" \n",
    "          group by \"AreaID\", \"SquirrelID\" \n",
    "          order by \"AreaID\") q left join areas a on q.\"AreaID\" = a.\"AreaID\" \n",
    "    group by q.\"AreaID\", a.\"AreaName\"\n",
    "    order by q.\"AreaID\") AS subquery\n",
    "\"\"\"\n",
    "\n",
    "# Reading data\n",
    "df = spark.read.jdbc(url=jdbc_url, table=query, properties=connection_properties)\n",
    "df.show()\n",
    "\n",
    "df.toPandas().to_csv('output/query_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2c4ccc-6b1f-4e43-83c1-934dfa741763",
   "metadata": {},
   "source": [
    "## 3. A count of \"Other Animal Sightings\" by Park."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a8603614-2de1-4bbf-8fdb-5e7b668551d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------------+-----+\n",
      "|          ParkName|      AnimalName|Total|\n",
      "+------------------+----------------+-----+\n",
      "|   Fort Tryon Park|       Cardinals|    1|\n",
      "|   Fort Tryon Park|            Dogs|    1|\n",
      "|   Fort Tryon Park|          Humans|    1|\n",
      "|   Fort Tryon Park|         Pigeons|    1|\n",
      "|J Hood Wright Park|            Dogs|    1|\n",
      "|J Hood Wright Park|           Hawks|    1|\n",
      "|J Hood Wright Park|          Humans|    1|\n",
      "|J Hood Wright Park|         Pigeons|    1|\n",
      "|J Hood Wright Park|             Rat|    1|\n",
      "|   Highbridge Park|            Dogs|    2|\n",
      "|   Highbridge Park|Downy Woodpecker|    1|\n",
      "|   Highbridge Park|          Humans|    1|\n",
      "|   Highbridge Park|         Pigeons|    1|\n",
      "|   Highbridge Park|          Robins|    1|\n",
      "|   Highbridge Park|      Song Birds|    1|\n",
      "|  St Nicholas Park|             Cat|    1|\n",
      "|  St Nicholas Park|            Dogs|    1|\n",
      "|  St Nicholas Park|          Humans|    1|\n",
      "|  St Nicholas Park|         Pigeons|    1|\n",
      "|    Riverside Park|            Dogs|    1|\n",
      "+------------------+----------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL query\n",
    "query = \"\"\"\n",
    "    (select p.\"ParkName\",  an.\"AnimalName\", count(*) as \"Total\"\n",
    "    from (select ps.\"ParkID\", pa.\"AnimalID\"\n",
    "          from parkstatusanimals pa left join parkstatus ps on pa.\"ParkStatusID\" = ps.\"ParkStatusID\"\n",
    "          order by ps.\"ParkID\") q left join animals an on q.\"AnimalID\" = an.\"AnimalID\" \n",
    "                                  left join parks p on q.\"ParkID\"::int = p.\"ParkID\"\n",
    "    group by q.\"ParkID\", p.\"ParkName\", q.\"AnimalID\",  an.\"AnimalName\" \n",
    "    order by q.\"ParkID\", an.\"AnimalName\") AS subquery\n",
    "\"\"\"\n",
    "\n",
    "# Reading data\n",
    "df = spark.read.jdbc(url=jdbc_url, table=query, properties=connection_properties)\n",
    "df.show()\n",
    "\n",
    "df.toPandas().to_csv('output/query_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c66556-11c8-44a4-a76c-946b8a1d0533",
   "metadata": {},
   "source": [
    "## 4. What is the most common activity for Squirrels? (e.g. eating, running, etc..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c86129f2-77c6-4b70-8c0f-66d863259a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "|Top|       TopActivities|\n",
      "+---+--------------------+\n",
      "|  1|            Foraging|\n",
      "|  2|            Climbing|\n",
      "|  3|              Eating|\n",
      "|  4|             Running|\n",
      "|  5|                  ND|\n",
      "|  6|             Chasing|\n",
      "|  7|             Sitting|\n",
      "|  8|            shouting|\n",
      "|  9|      Defending tree|\n",
      "| 10|             Digging|\n",
      "| 11|             up tree|\n",
      "| 12|            Sleeping|\n",
      "| 13|             Burying|\n",
      "| 14|      Climbing fence|\n",
      "| 15|   Digging something|\n",
      "| 16|Very carefully wa...|\n",
      "| 17|Sitting at attention|\n",
      "| 18|            Cleaning|\n",
      "| 19|         Watching #2|\n",
      "| 20|             Nesting|\n",
      "+---+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL query\n",
    "query = \"\"\"\n",
    "    (SELECT ROW_NUMBER() OVER(ORDER BY COUNT(*) DESC) AS \"Top\", \n",
    "    a.\"ActivityName\" as \"TopActivities\"\n",
    "    FROM squirrelactivities s\n",
    "    LEFT JOIN activities a ON s.\"ActivityID\" = a.\"ActivityID\"\n",
    "    GROUP BY s.\"ActivityID\", a.\"ActivityName\"\n",
    "    ORDER BY COUNT(*) desc) AS subquery\n",
    "\"\"\"\n",
    "\n",
    "# Reading data\n",
    "df = spark.read.jdbc(url=jdbc_url, table=query, properties=connection_properties)\n",
    "df.show()\n",
    "\n",
    "df.toPandas().to_csv('output/query_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdb52ae-7ace-43a4-84c3-d773b22d1206",
   "metadata": {},
   "source": [
    "## 5. A count of all Primary Fur Colors by Park."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "027b05aa-2551-4e05-998a-2411e7392d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+----------------+-----+\n",
      "|ParkID|            ParkName|PrimaryFurColors|Total|\n",
      "+------+--------------------+----------------+-----+\n",
      "|     1|     Fort Tryon Park|           Black|    1|\n",
      "|     1|     Fort Tryon Park|            Gray|   11|\n",
      "|     2|  J Hood Wright Park|        Cinnamon|    1|\n",
      "|     2|  J Hood Wright Park|            Gray|   23|\n",
      "|     3|     Highbridge Park|            Gray|   17|\n",
      "|     4|    St Nicholas Park|           Black|    2|\n",
      "|     4|    St Nicholas Park|            Gray|   13|\n",
      "|     5|      Riverside Park|            Gray|   56|\n",
      "|     6|  Marcus Garvey Park|           Black|    2|\n",
      "|     6|  Marcus Garvey Park|            Gray|   32|\n",
      "|     7| Madison Square Park|            Gray|   11|\n",
      "|     8|   Union Square Park|        Cinnamon|    5|\n",
      "|     8|   Union Square Park|            Gray|   11|\n",
      "|     9|Stuyvesant Square...|           Black|    6|\n",
      "|     9|Stuyvesant Square...|            Gray|   19|\n",
      "|    10|Washington Square...|            Gray|   55|\n",
      "|    11|Tompkins Square Park|           Black|    8|\n",
      "|    11|Tompkins Square Park|            Gray|  110|\n",
      "|    12|John V Lindsay Ea...|           Black|    1|\n",
      "|    12|John V Lindsay Ea...|            Gray|   11|\n",
      "+------+--------------------+----------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL query\n",
    "query = \"\"\"\n",
    "    (select s.\"ParkID\",  p.\"ParkName\", c.\"ColorName\" as \"PrimaryFurColors\", count(*) as \"Total\"\n",
    "    from squirrels s left join colors c on s.\"SquirrelPrimFurColorID\" = c.\"ColorID\" \n",
    "                     left join parks p  on s.\"ParkID\" = p.\"ParkID\" \n",
    "    group by s.\"ParkID\", s.\"SquirrelPrimFurColorID\", c.\"ColorName\", p.\"ParkName\"\n",
    "    order by s.\"ParkID\", count(*), c.\"ColorName\") AS subquery\n",
    "    \"\"\"\n",
    "\n",
    "# Reading data\n",
    "df = spark.read.jdbc(url=jdbc_url, table=query, properties=connection_properties)\n",
    "df.show()\n",
    "\n",
    "df.toPandas().to_csv('output/query_5.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
